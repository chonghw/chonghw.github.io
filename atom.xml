<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>High Performance</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-05-07T02:25:44.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Obsolete</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>transfer</title>
    <link href="http://yoursite.com/blog/2017/05/07/transfer/"/>
    <id>http://yoursite.com/blog/2017/05/07/transfer/</id>
    <published>2017-05-07T02:25:44.000Z</published>
    <updated>2017-05-07T02:25:44.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>深入探索并发编程系列(十)-Weakly-ordered CPU的由来</title>
    <link href="http://yoursite.com/blog/2016/12/08/weakly-ordered-cpu/"/>
    <id>http://yoursite.com/blog/2016/12/08/weakly-ordered-cpu/</id>
    <published>2016-12-08T11:23:49.000Z</published>
    <updated>2016-12-10T02:05:39.000Z</updated>
    
    <content type="html"><![CDATA[<p>在这一系列博客中，我已经详细讨论了<a href="">lock-free编程</a>相关的一系列主题，比如<a href="http://www.chongh.wiki/blog/2016/09/28/acquireandrelease/" target="_blank" rel="external">Acquire与Release语义</a>以及<a href="http://www.chongh.wiki/blog/2016/10/30/memorymodel/" target="_blank" rel="external">Weakly-ordered CPUs</a>. 我已经努力尝试把这些主题讲的更加地通俗易懂，但大家都知道，Talk is cheap.没有言语比具体的例子更能把问题说清楚。</p>
<a id="more"></a>
<p>如果要概括weakly-ordered CPU，可以这么说:一个CPU core按照一定的顺序修改变量，然而其他的CPU core却可以看到对该变量不同的修改顺序<sup>注1</sup>. 这就是我要在这篇文章中使用纯C++11来讲述的内容。</p>
<p>对于一般程序来说，x86/64处理器家族从Intel到AMD都不具备这种特性。因此我们别想着在现有的桌面系统或者笔记本上来阐述这种问题了。我们需要的只是一个weakly-ordered的多核设备。幸运的是，在我口袋里恰好就有这么一台设备。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/weaklyordered1.png" alt=""></p>
<p>Iphone4s就能满足要求。它运行在一个多核ARM处理器上，而这种ARM架构就是weakly-ordered.</p>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>我们的实验由一个整型变量<code>sharedValue</code>以及保护它的锁(mutex)组成。我们来生成两个线程，并且每个线程都会对<code>sharedValue</code>做递增操作1千万次。</p>
<p>我们不要让线程一直等待锁(mutex)而阻塞，而是让每个线程都会忙碌地重复做一些事情(比如只是等待CPU时钟)，并试着在随机的时间里加锁。如果加锁成功，那线程就会将<code>shareValue</code>递增，否则，就会返回到原处继续做一些忙碌地工作。下面是其伪代码:</p>
<pre><code>count = 0
while count &lt; 10000000:
doRandomAmountOfBusyWork()
if tryLockMutex():
    // The lock succeeded
    sharedValue++
    unlockMutex()
    count++
endif
endwhile
</code></pre><p>每个线程都运行在不同的CPU核中，timeline应该是像下图这样的。每个红色区域代表一个成功的上锁和递增操作，灰色代表加锁失败，因为这时另一个线程已经拥有这把锁了。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/weaklyordered2.png" alt=""></p>
<p>需要强调的是，<a href="http://www.chongh.wiki/blog/2016/06/27/lightweightmutex/" target="_blank" rel="external">锁只是一个概念</a>，有<a href="http://www.chongh.wiki/blog/2016/07/04/writelightweightmutex/" target="_blank" rel="external">许多</a>实现锁的方法。我们采用std::mutex中提供的实现方法，当然了，保证其中一切都会运行正确。倘若真是那样，我就没什么可以跟你们讲的了。不如这样，我们来实现一个常规的锁-我们来看看<a href="http://www.chongh.wiki/blog/2016/10/30/memorymodel/" target="_blank" rel="external">弱硬件执行顺序</a>的结果。直观上来看，当在线程间有个“close shave”时，内存乱序发生的可能性是最高的。举个例子，在上图中，当一个线程正好就在另一个线程释放锁的那一时刻获取锁，这种现象就叫做”close shave”。</p>
<p>Xcode的最新版本对C++11线程和原子类型支持非常好，那我们就用它吧。所有的C++标识符都定义在<code>std</code>命名空间中，我们假设<code>using namespace std</code>提前定义在了代码中某处。</p>
<h3 id="一把诡异的简单锁"><a href="#一把诡异的简单锁" class="headerlink" title="一把诡异的简单锁"></a>一把诡异的简单锁</h3><p>我们的锁由一个整型<code>flag</code>组成，1表示锁被持有，0表示不被持有。为了保证锁的独占权，一个线程只能在<code>flag</code>值为0的时候才能将其设置成1，而且这种操作必须保证原子性。为了做到这些，我们将<code>flag</code>定义为C++11的原子类型，<code>atomic&lt;int&gt;</code>，并采用<a href="http://preshing.com/20120612/an-introduction-to-lock-free-programming/#atomic-rmw" target="_blank" rel="external">read-modify-write</a>操作:</p>
<pre><code>int expected = 0;
if (flag.compare_exchange_strong(expected, 1, memory_order_acquire))
{
    // The lock succeeded
}
</code></pre><p>上面代码中用的<code>memory_order_acquire</code>参数被认为是执行顺序约束的(ordering constraint）.我们在操作中采用acquire语义，用来保证我们能从持有锁的前一个线程中获取最新的共享值<sup>注2</sup>。</p>
<p>为了释放锁，我们执行下面的操作:</p>
<pre><code>flag.store(0, memory_order_release);
</code></pre><p>上面操作使用<code>memory_order_acquire</code>执行顺序约束将<code>flag</code>设置回0了，其采用了release语义。<a href="http://www.chongh.wiki/blog/2016/09/28/acquireandrelease/" target="_blank" rel="external">Acquire与Release语义</a>必须成对使用,用来确保共享值能从一个线程中传播到另一个线程中<sup>注3</sup>。</p>
<h3 id="如果不使用Acquire和Release语义"><a href="#如果不使用Acquire和Release语义" class="headerlink" title="如果不使用Acquire和Release语义"></a>如果不使用Acquire和Release语义</h3><p>现在，我们不限定任何的正确执行顺序约束，使用C++11重写上述实验,只要在两处都放置’memory_order_relaxed`。这意味着C++ 11编译器不会强制任何特殊的内存执行顺序，<a href="http://www.chongh.wiki/blog/2016/09/19/sourcecontrol/" target="_blank" rel="external">任何类型的乱序</a>都是允许的。</p>
<pre><code>void IncrementSharedValue10000000Times(RandomDelay&amp; randomDelay)
{
int count = 0;
while (count &lt; 10000000)
{
    randomDelay.doBusyWork();
    int expected = 0;
    if (flag.compare_exchange_strong(expected, 1, memory_order_relaxed))
    {
        // Lock was successful
        sharedValue++;
        flag.store(0, memory_order_relaxed);
        count++;
    }
}
}
</code></pre><p>这时，看看编译器产生的ARM汇编代码能告诉我们很多信息，在Release中，使用Xcode中的反汇编视图:</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/weaklyordered3.png" alt=""></p>
<p>如果你对汇编不是很熟悉，也不必担心。所有需要知道的就是编译器是否在共享变量中对任何操作重新排序了。这里包括对<code>flag</code>的两种操作以及对<code>sharedValue</code>的递增操作。在上图中，我标明了相应区域对应的汇编代码。正如你所知，我们是幸运的：尽管<code>memory_order_relaxed</code>参数意味着编译器可以对那些操作重新排序，但编译器并没有这么做.</p>
<p>我已经给出了一个样例程序来无限循环这个实验，并在每一次运行结束后将<code>sharedValue</code>的最终值打印出来。如果你想看源码并自己运行，可以在<a href="https://github.com/preshing/AcquireRelease" target="_blank" rel="external">github</a>上下载。</p>
<p>下面是iphone正在努力的运行这个实验</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/weaklyordered4.png" alt=""></p>
<p>这是Xcode输出框中的输出:</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/weaklyordered5.png" alt=""></p>
<p>动手检验一下！尽管两个线程都分别执行了递增操作1千万次,<code>sharedValue</code>的最终值一直小于2千万。并且，汇编指令的执行顺序和C++中定义在共享变量中的执行顺序操作是一致的。</p>
<p>你可能会觉得，这些结果可能是因为CPU上的内存乱序导致的。为了指出一种可能的乱序-实际上有很多种可能-<code>str.w r0, [r11]</code>(sharedValue写操作)与内存的交互可能会和<code>str r5, [r6]</code>(将flag写入0）发生乱序。换句话说，在程序结束之前，锁能被有效地释放。正如我们所见，结果是另一个线程可以自由的擦除由这个线程对值的修改，导致在实验结束时<code>sharedValued</code>的不一致。</p>
<h3 id="正确使用Acquire与Release语义"><a href="#正确使用Acquire与Release语义" class="headerlink" title="正确使用Acquire与Release语义"></a>正确使用Acquire与Release语义</h3><p>要修正上述的例子，意味着要重新放回正确的C++11内存执行顺序约束：</p>
<pre><code>void IncrementSharedValue10000000Times(RandomDelay&amp; randomDelay)
{
int count = 0;
while (count &lt; 10000000)
{
    randomDelay.doBusyWork();
    int expected = 0;
    if (flag.compare_exchange_strong(expected, 1, memory_order_acquire))
    {
        // Lock was successful
        sharedValue++;
        flag.store(0, memory_order_release);
        count++;
    }
}
}
</code></pre><p>编译器插入一系列<code>dmb ish</code>指令，这些指令在ARMv7指令集中充当内存屏障。我不是个ARM专家–欢迎评论–但可以保险的假设这个指令很像PowerPC上的<code>lwsync</code>指令，为<code>compare_exchange_strong</code>上的acquire语义和<code>store</code>上的release语义提供了所有<a href="http://www.chongh.wiki/blog/2016/09/19/sourcecontrol/" target="_blank" rel="external">内存屏障类型</a><sup>注4</sup>。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/weaklyordered6.png" alt=""></p>
<p>这次，我们可爱的自制锁的确保护了<code>sharedValue</code>，确保每次加锁时所有的修改都从一个线程中安全的传播到了另一个线程中<sup>注5</sup>。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/weaklyordered7.png" alt=""></p>
<p>如果你仍然无法理解这个实验发生了什么。我建议你看看<a href="http://www.chongh.wiki/blog/2016/09/19/sourcecontrol/" target="_blank" rel="external">这篇</a>文章。就类比而言，你可以想象一下，两个工作站其中每个都有<code>sharedValue</code>和<code>flag</code>的本地副本，需要一些其它的工作来确保它们是同步的。个人而言，用这种方法将其可视化是很有帮助的。</p>
<p>我想重述一遍，我们在这里看到的内存乱序只能在多核或多处理器设备中才能发生<sup>注6</sup>。如果你把这个编译好的程序运行在Iphone3GS或更早一代的ipad中，它们都使用同样的ARMv7架构但只有一个CPU核，你也不会看到<code>sharedValue</code>最后结果的任何不匹配性。</p>
<h3 id="有趣的笔记"><a href="#有趣的笔记" class="headerlink" title="有趣的笔记"></a>有趣的笔记</h3><p>你可以把这个<a href="https://github.com/preshing/AcquireRelease" target="_blank" rel="external">示例程序</a>运行在任何x86/x64架构上的Window,MacOS或Linux机器上。就算是在一个多核系统中，除非是你的编译器在一些特殊指令上执行了乱序，否则你是不会看到任何运行时的内存乱序的。当我用Visual Studio2012测试时，并没有发生内存乱序。那是因为x86/x64处理器通常都被认为是<a href="http://www.chongh.wiki/blog/2016/10/30/memorymodel/" target="_blank" rel="external">strongly-ordered</a>：当一个CPU核执行一系列写操作时，每个其它CPU核都会看到它们在被写入时顺序的值变化<sup>注7</sup>。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/weaklyordered8.png" alt=""></p>
<p>上图为了说明如果不了解C++11原子类型，就很容易错误的使用，。很简单，因为它只有在一个特殊的处理器和工具链中才能正确运行</p>
<p>碰巧的是，Visual Studio2012的发行版对这个示例程序会产生非常糟糕的x86机器代码。在多核系统上使用lock-free编程，提高性能是最首要原因。现在有足够的理由让我无法忍受在Window平台上用C++11原子类型了。正如<a href="http://preshing.com/20121019/this-is-why-they-call-it-a-weakly-ordered-cpu/#comment-61574" target="_blank" rel="external">评论</a>中提到的，VS2012专业版的最新版本产生的机器代码会好很多了。</p>
<p>这篇文章是前期文章讨论x86/64上的<a href="http://www.chongh.wiki/blog/2016/08/11/memoryreorder/" target="_blank" rel="external">StoreLoad乱序</a>的续集。从我的经验来看，#StoreLoad在实际运用中并不如这里提到的执行顺序约束用的频繁</p>
<p>最后，我不是第一个在实际运用当中阐述弱硬件执行顺序的人，但我可能是第一个使用C++11来阐述的人。之前<a href="http://wanderingcoder.net/2011/04/01/arm-memory-ordering/" target="_blank" rel="external">Pierre Lebeaupin</a>和<a href="http://ridiculousfish.com/blog/posts/barrier.html" target="_blank" rel="external">ridiculousfish</a>的一些文章采用了不同的实验来解释相同的现象。</p>
<h2 id="译者注"><a href="#译者注" class="headerlink" title="译者注"></a>译者注</h2><p>注1:也就是说，假如CPU core1执行如下语句：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">1</span>;</span><br><span class="line">b = <span class="number">2</span>;</span><br></pre></td></tr></table></figure>
<p>CPU core2可能先看到b == 2 ，然后才是 a == 1</p>
<p>注2: acquire对应invalid queue。 release对应store buffer。</p>
<p>注3: 这里的配对，并不是严格的一一对应。也就是说，CPU core1修改共享变量时使用release语义，CPU core2、 core3、core4都用acquire语义去读。</p>
<p>那么core1和core2、core3、core4都配对。</p>
<p>注4: 这里值得一提的时，gcc下的<code>__sync_compare_and_swap</code>和<code>__sync_fetch_and_add</code>这些原子操作在X86下会自带一个memory barrier。所以这些原子操作之后没必要再加memory barrier了。</p>
<p>注5: 其实这也是锁的必备的一个语义。一般说来，锁要提供三种语义：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">b++;</span><br><span class="line">lock.lock();</span><br><span class="line">a++;</span><br><span class="line">d++;</span><br><span class="line">lock.unlock();</span><br><span class="line">c++</span><br></pre></td></tr></table></figure>
<p>语义1:当线程1更新完a(也包括d)的值之后释放锁，线程2进入临界区必须读到a(也包括d)的新值，也就是线程1更新完之后的值。可以认为是acquire release或者happen before语义。</p>
<p>语义2:同一时刻，a++这条语句只能有一个线程在执行。可以认为是临界语义或者互斥语义。</p>
<p>语义3:必须保证a++不会被乱序到b++处执行，也不能乱序到c++处执行。这个自然也是临界语义或者互斥语义的一部分，因为如果乱序，那么无临界区可言了。但是读者诸君要注意到，以下这样的乱序是完全可以的、合法的：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">b++;</span><br><span class="line">lock.lock();</span><br><span class="line">d++;</span><br><span class="line">a++;</span><br><span class="line">lock.unlock();</span><br><span class="line">c++;</span><br></pre></td></tr></table></figure>
<p>或者：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lock.lock();</span><br><span class="line">b++;</span><br><span class="line">a++;</span><br><span class="line">d++;</span><br><span class="line">c++;</span><br><span class="line">lock.unlock();</span><br></pre></td></tr></table></figure></p>
<p>注6：也就是说，单核多线程、多核单线程程序不用担心memory reordering问题，只有多核多线程才需要小心谨慎。为什么呢？</p>
<p>更进一步，读者可能还会有两个疑问：</p>
<p>1，为什么CPU要乱序执行，难道是考虑性能吗？那为什么乱序就能提升性能？</p>
<p>2，为什么在Intel X86/64架构下，就只有写读（Store Load）发生乱序呢？读读呢？读写呢？</p>
<p>要明白这两个问题，我们首先得知道cache coherency，也就是所谓的cache一致性。</p>
<p>在现代计算机里，一般包含至少三种角色：cpu、cache、内存。一般说来，内存只有一个；CPU Core有多个；cache有多级，cache的基本块单位是cacheline，大小一般是64B-256B。</p>
<p>每个cpu core有自己的私有的cache(有一级cache是共享的)，而cache只是内存的副本。那么这就带来一个问题：如何保证每个cpu core中的cache是一致的？</p>
<p>在广泛使用的cache一致性协议即MESI协议中，cacheline有四种状态：Modified、Exclusive、Shared、Invalid，分别表示修改、独占、共享、无效。</p>
<p>当某个cpu core写一个内存变量时，往往是（先）只修改cache，那么这就会导致不一致。为了保证一致，需要先把其他core的对应的cacheline都invalid掉，给其他core们发送invalid消息，然后等待它们的response。</p>
<p>这个过程是耗时的，需要执行写变量的core等待，阻塞了它后面的操作。为了解决这个问题，cpu core往往有自己专属的store buffer。</p>
<p>等待其他core给它response的时候，就可以先写store buffer，然后继续后面的读操作，对外表现就是写读乱序。</p>
<p>因为写操作是写到store buffer中的，而store buffer是私有的，对其他core是透明的，core1无法访问core2的store buffer。因此其他core读不到这样的修改。</p>
<p>这就是大概的原理。MESI协议非常复杂，背后的技术也很有意思。</p>
<p>注7:X86写写不乱序；也就是说对于</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">1</span>;</span><br><span class="line">b = <span class="number">3</span>;</span><br></pre></td></tr></table></figure>
<p>其他cpu core将先看到a == 1再看到 b == 3。（不考虑编译器优化）</p>
<h3 id="Acknowledgements"><a href="#Acknowledgements" class="headerlink" title="Acknowledgements"></a>Acknowledgements</h3><p>本文由微博用户 <a href="http://weibo.com/2767520802/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="external">Diting0x</a> 与 <a href="http://weibo.com/yebangyu" target="_blank" rel="external">睡眼惺忪的小叶先森</a> 共同完成，在原文的基础上添加了许多精华注释，帮助大家理解。</p>
<p>感谢好友<a href="http://weibo.com/u/1707881862?topnav=1&amp;wvr=6&amp;topsug=1&amp;is_all=1" target="_blank" rel="external">小伙伴-小伙伴儿 </a>阅读了初稿，并给出宝贵的意见。</p>
<p>感谢微博用户@白云展翅海面飞指出一个勘误</p>
<p>原文： <a href="http://preshing.com/20121019/this-is-why-they-call-it-a-weakly-ordered-cpu/" target="_blank" rel="external">http://preshing.com/20121019/this-is-why-they-call-it-a-weakly-ordered-cpu/</a></p>
<p>本文遵守Attribution-NonCommercial-NoDerivatives 4.0 International License (CC BY-NC-ND 4.0)<br>仅为学习使用，未经博主同意，请勿转载<br>本系列文章已经获得了原作者preshing的授权。版权归原作者和本网站共同所有</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在这一系列博客中，我已经详细讨论了&lt;a href=&quot;&quot;&gt;lock-free编程&lt;/a&gt;相关的一系列主题，比如&lt;a href=&quot;http://www.chongh.wiki/blog/2016/09/28/acquireandrelease/&quot;&gt;Acquire与Release语义&lt;/a&gt;以及&lt;a href=&quot;http://www.chongh.wiki/blog/2016/10/30/memorymodel/&quot;&gt;Weakly-ordered CPUs&lt;/a&gt;. 我已经努力尝试把这些主题讲的更加地通俗易懂，但大家都知道，Talk is cheap.没有言语比具体的例子更能把问题说清楚。&lt;/p&gt;
    
    </summary>
    
      <category term="High-performance" scheme="http://yoursite.com/categories/High-performance/"/>
    
    
  </entry>
  
  <entry>
    <title>深入探索并发编程系列(九)-弱/强内存模型</title>
    <link href="http://yoursite.com/blog/2016/10/30/memorymodel/"/>
    <id>http://yoursite.com/blog/2016/10/30/memorymodel/</id>
    <published>2016-10-30T01:21:50.000Z</published>
    <updated>2016-11-01T16:58:10.000Z</updated>
    
    <content type="html"><![CDATA[<p>存在许多种内存乱序<sup>注1</sup>，但它们发生的频率并不都是一样的。这取决于你的目标处理器以及开发工具链。</p>
<a id="more"></a>
<p>对于特定的处理器和工具链，内存模型能告诉你的源代码在运行时可能会发生哪种类型的内存乱序。在脑海中一定要时刻记住，只有在使用无锁编程技术时，内存乱序的效果才能显现出来。</p>
<p>学习了一段时间的内存模型后(大部分是通过阅读网上的资源并进行实验来验证)，我将它们概括为以下四种类型。下图中，每种内存模型都囊括涵盖它左边的内存模型所能提供的所有保证，并提供了更多的保证<sup>注2</sup>。 根据大部分使用弱内存模型与强内存模型这些术语的方式，我在它们之间划了一条明显的界限。继续往下读就能知道我为什么这么做了。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/memorymodel1.png" alt=""></p>
<p>上图中每个物理设备代表一种硬件内存模型。硬件内存模型能告诉你对于汇编(或者机器)代码在运行期间会出现哪种内存执行顺序</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/memorymodel2.png" alt=""></p>
<p>对于内存乱序情况，每种处理器家族都有不同的处理习惯，而那些习惯只有在多核或多处理器的配置环境下才能显现出来。考虑到现在的主流都是多核的，它们之间会有很多相似性。</p>
<p>同样也存在许多软件内存模型。从技术上来说，只要你用C11,C++11或Java编写（调试)代码，与之关联的是软件内存模型。尽管如此，对硬件内存模型的一般理解也迟早会派上用场。它能帮助你解释调试过程中不可预料的行为（可能正因为它很重要），能识别错误代码在不走运的情况下是如何在特定处理器与工具链上运行正确的。</p>
<h3 id="弱内存模型"><a href="#弱内存模型" class="headerlink" title="弱内存模型"></a>弱内存模型</h3><p>在弱内存模型中，有可能会出现我在上一篇文章中用资源控制类比来描述的所有<a href="http://www.chongh.wiki/blog/2016/09/19/sourcecontrol/" target="_blank" rel="external">四种内存乱序</a>. 只要不改变单个独立线程的行为，任何的读/写操作与其它的读/写操作都有可能发生乱序。实际上，编译器或者处理器都可能产生乱序。</p>
<p>当处理器是弱硬件内存模型时，我们更倾向于说它是<code>weakly ordered</code>或<code>weak ordering</code>。 我们也可以说它有个宽松的内存模型。提到弱内存模型处理器，令人敬仰的DEC Alpha处理器是人人爱用的例子。现在主流的处理器中，没有比它更弱的内存模型了。</p>
<p>受Alpha多方面的影响，C11与C++11编程语言是一种弱的软件内存模型。如果你正在用x86/64等强类型处理器家族，当在这些语言中使用底层的原子操作时并不会受到影响<sup>注3</sup>。我之前说过，只要是为了阻止编译器乱序，你必须要指定正确的<a href="http://www.chongh.wiki/blog/2016/09/28/acquireandrelease/" target="_blank" rel="external">内存执行顺序限制</a>.</p>
<h3 id="带有数据依赖执行顺序的弱内存模型"><a href="#带有数据依赖执行顺序的弱内存模型" class="headerlink" title="带有数据依赖执行顺序的弱内存模型"></a>带有数据依赖执行顺序的弱内存模型</h3><p>随着时间变化，尽管Alpha已经变得无关紧要了，现代的CPU家族仍有保留了一些会执行弱硬件执行顺序的传统：</p>
<ul>
<li><strong>ARM</strong> 成千上万的智能手机和平板电脑都在使用，在多核环境下变得越来越受欢迎</li>
<li><strong>PowerPC</strong> xbox 360已经在多核环境下贡献了七千万的生存空间</li>
<li><strong>Itanium</strong> 微软在Windows下不再支持，但在HP服务器上仍能被Linux支持</li>
</ul>
<p>除了程序员特别感兴趣的常识细节也就是它们能保持数据依赖执行顺序这点之外，这些处理器家族在不同的方式上都和Alpha有着一样弱的内存模型。这是什么意思呢？意味着如果你用C/C++写A-&gt;B,你能一直确保B的值至少和A的值一样新。Alpha却不能确保<sup>注4</sup>。在这里我不过多叙述这种数据依赖执行顺序，只提一提Linux RCU机制非常依赖这个性质。</p>
<h3 id="强内存模型"><a href="#强内存模型" class="headerlink" title="强内存模型"></a>强内存模型</h3><p>我们首先来看看硬件内存模型。强内存模型与弱内存模型最大的差别在哪里呢？在这个问题上大家可能会有一些分歧,但我的感觉是80%的场合下，人们说的都是同一件事。因此，我给出下面这个定义：</p>
<p>强内存模型意味着每个机器指令都能隐式的包含Acquire与Release语义。结果是，当一个CPU核执行一系列的写操作时，其它的每一个CPU核看见的都是那些值都以它们被写入时的顺序在改变。</p>
<p>这些都不难理解。只要想象资源控制类比中的核心观点,所有的修改有序地提交给共享内存(没有写写乱序)，有序地从共享内存取出(没有读读乱序)，并且指令总有序的执行(没有读写乱序)。然而写读乱序还是有可能发生。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/memorymodel3.png" alt=""></p>
<p>从上述的定义可以看出，x86/64处理器家族一向是强内存模型(strong ordered）的。有时候有例外，但在大部分情况下，对于程序员来说，这些例子都可以忽略。x86/x64处理器能乱序执行指令，但那属于硬件实现的范畴。而真正有意义的是它仍能保证内存的交互是有序的，因此在多核环境下，我们仍然可以把它认为是强内存模型的。从历史角度来看，标准在不断地发展，可能会给大家带来一些困扰。</p>
<p>很明显，当SPARC处理器运行在TSO模式中，是另一种强硬件内存模型的例子。TSO代表Total Store Order，相比我上面给出的定义来看，这是一种微妙的方式，意味着对所有cpu核来说，关于写内存操作，都有一个单一确定的全序<sup>注5</sup>。X86/X64也有这个性质，可以参考Intel x86/x64系统结构手册中Volume 3, §8.2.3.6-8的例子。从那里我可以得出结论，TSO性质不总是lock-free程序员对底层感兴趣的最直接部分，但这在对顺序一致性的理解上又迈进了一步。</p>
<h3 id="顺序一致性"><a href="#顺序一致性" class="headerlink" title="顺序一致性"></a>顺序一致性</h3><p>在顺序一致性内存模型中，没有内存乱序。这看起来就像是整个程序的执行被缩减到每个线程中指令的顺序交错。具体来说，<a href="http://www.chongh.wiki/blog/2016/08/11/memoryreorder/" target="_blank" rel="external">这篇文章</a>中r1 = r2 = 0 的结果就变得不可能了<sup>注6</sup>。</p>
<p>如今你很难找到一个现代的多核设备能在硬件级别保证顺序一致性。然而，似乎在1989年至少有一种能保证顺序一致性的多处理器机器：基于386的<a href="http://www.vogons.org/viewtopic.php?t=23842#178666" target="_blank" rel="external">Compaq SystemPro</a>。根据Intel文档，386还不够先进到能在运行期间执行任意的内存乱序。</p>
<p>在任何情况下，当使用高级编程语言，顺序一致性只有在作为软件内存模型时才变得有趣。在Java5或更高版本中，你可以将共享变量声明为volatile。在C++11中,当在原子数据类型执行操作的时候，可以使用默认的顺序约束，也就是memory_order_seq_cst<sup>注7</sup>。如果这么做了，工具链会限制编译器乱序并发出CPU特定的指令来充当合适的memory barrier。在这种方式下，尽管是在弱内存模型的多核设备上,也会模拟出顺序一致性的内存模型。如果你读了Herlihy &amp; Shavit’s的 <a href="https://www.amazon.com/gp/product/0123973376/ref=as_li_ss_tl?ie=UTF8&amp;tag=preshonprogr-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0123973376" target="_blank" rel="external">The Art of Multiprocessor Programming</a>,要注意那里的大部分例子都假设顺序一致性的软件内存模型。</p>
<h3 id="更多细节"><a href="#更多细节" class="headerlink" title="更多细节"></a>更多细节</h3><p>要填完有关内存模型的坑，还有许多其它微妙的细节，但以我的经验来看，当在应用层上写无锁代码时，这些都变得没什么意思了。存在一些控制依赖，因果一致性和不同的内存乱序类型。然而，大部分的讨论都能归于我上面总结的四种主要类型里。</p>
<p>如果你真的想探究处理器内存模型的细节，并且你能在吃早餐的时候还想琢磨一些正式的逻辑，你可以看看剑桥大学的非常精细的<a href="http://www.cl.cam.ac.uk/~pes20/weakmemory/" target="_blank" rel="external">工作</a><br>Paul McKenney写了它们的工作和相关工具的一些<a href="http://lwn.net/Articles/470681/" target="_blank" rel="external">概览</a><sup>注8</sup></p>
<h3 id="译者注"><a href="#译者注" class="headerlink" title="译者注"></a>译者注</h3><p>注1：比如说写写乱序、写读乱序、读读乱序、读写乱序等等。</p>
<p>注2：也就是说从右到左模型越来越弱，限制越来越松，乱序发生的越来越多。</p>
<p>注3：即使在X86/X64下，还是得注意可能的写读乱序。</p>
<p>注4：举个关于data dependency的例子，来说明在DEC Alpha下编程有多么的困难和tricky。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">初始化</span><br><span class="line"><span class="keyword">int</span> A = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span> B = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">int</span> C = <span class="number">3</span>;</span><br><span class="line"><span class="keyword">int</span> *P = &amp;A;</span><br><span class="line"><span class="keyword">int</span> *Q = &amp;B;</span><br><span class="line"><span class="comment">//cpu1</span></span><br><span class="line">B = <span class="number">4</span>;</span><br><span class="line">CPU_BARRIER();</span><br><span class="line">P = &amp;B;</span><br><span class="line"><span class="comment">//cpu2</span></span><br><span class="line">Q = P;</span><br><span class="line">D = *Q</span><br></pre></td></tr></table></figure>
<p>从直觉上说，Q最后要么等于&amp;A，要么等于&amp;B。也就是说：</p>
<p>Q == &amp;A， D == 1</p>
<p>或者</p>
<p>Q == &amp;B， D == 4</p>
<p>但是，让人吃惊的是，DEC Alpha下，可能出现</p>
<p>Q == &amp;B， D == 2的情形，原因是，虽然CPU1按照顺序执行完两条语句先后对B和P进行了修改，但CPU2可能先感知到P的变化，读到了P的新值，然后才是B的新值。因此，为了防止这样的问题，需要加一个data dependency barrier。</p>
<p>注5：偏序、全序什么意思？读者诸君如果忘记，可以简单复习下大学的离散数学教材。</p>
<p>注6：对顺序一致性(Sequential Consistency)感兴趣的读者，可以参考我们写的<a href="http://www.yebangyu.org/blog/2016/01/09/memoryconsistencyandcachecoherence/" target="_blank" rel="external">这篇</a>博客。</p>
<p>注7：C++11引入的feature。在C++11中，除了这里提到的<code>std::memory_order_seq_cst</code>之外，还有如下的内存序选项：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">memory_order_relaxed,</span><br><span class="line">memory_order_consume,</span><br><span class="line">memory_order_acquire,</span><br><span class="line">memory_order_release,</span><br><span class="line">memory_order_acq_rel,</span><br></pre></td></tr></table></figure>
<p>关于它们的语义和用法，请继续关注我们的深入探索并发编程系列，或者参考《C++ Concurrency In Action》这本书第五章。</p>
<p>注8：谈到C++ memory model，很难绕开一个大牛：Mark John Batty。对C++11的memory model感兴趣的读者，如果想深入研究其中的理论和形式化部分，可以参考他的<a href="http://www.sigplan.org/Awards/Dissertation/2015_batty.pdf" target="_blank" rel="external">论文</a>。</p>
<h3 id="Acknowledgement"><a href="#Acknowledgement" class="headerlink" title="Acknowledgement"></a>Acknowledgement</h3><p>本文由 <a href="http://weibo.com/2767520802/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="external">Diting0x</a> 与 <a href="http://weibo.com/yebangyu" target="_blank" rel="external">睡眼惺忪的小叶先森</a> 共同完成，在原文的基础上添加了许多精华注释，帮助大家理解。</p>
<p>感谢好友<a href="http://weibo.com/u/1707881862?topnav=1&amp;wvr=6&amp;topsug=1&amp;is_all=1" target="_blank" rel="external">小伙伴-小伙伴儿 </a>阅读了初稿，并给出宝贵的意见。</p>
<p>原文： <a href="http://preshing.com/20120930/weak-vs-strong-memory-models/" target="_blank" rel="external">http://preshing.com/20120930/weak-vs-strong-memory-models/</a></p>
<p>本文遵守Attribution-NonCommercial-NoDerivatives 4.0 International License (CC BY-NC-ND 4.0)<br>仅为学习使用，未经博主同意，请勿转载<br>本系列文章已经获得了原作者preshing的授权。版权归原作者和本网站共同所有</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;存在许多种内存乱序&lt;sup&gt;注1&lt;/sup&gt;，但它们发生的频率并不都是一样的。这取决于你的目标处理器以及开发工具链。&lt;/p&gt;
    
    </summary>
    
      <category term="High-performance" scheme="http://yoursite.com/categories/High-performance/"/>
    
    
  </entry>
  
  <entry>
    <title>深入探索并发编程系列(八)-Acquire与Release语义</title>
    <link href="http://yoursite.com/blog/2016/09/28/acquireandrelease/"/>
    <id>http://yoursite.com/blog/2016/09/28/acquireandrelease/</id>
    <published>2016-09-28T03:11:52.000Z</published>
    <updated>2016-11-01T16:59:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>一般来说，在无锁(lock-free)<sup>注1</sup>编程中，线程有两种方法来操作共享内存：线程间相互竞争一种资源或者相互合作传递消息。Acquire与Release语义对后者来说很关键：保证在线程间可靠地相互传递消息。实际上，我大胆地猜测，不正确的或者缺乏Acquire与Release语义是导致无锁编程产生错误的最常见 原因。</p>
<a id="more"></a>
<p>在这篇文章中，我会去探讨许多在C++中获得Acquire与Release 语义的方法。还会简单介绍一下C++11原子库标准。所以，你事先不必具备这方面的知识。简明起见，这里的讨论仅限于非<a href="http://preshing.com/20120612/an-introduction-to-lock-free-programming/#sequential-consistency" target="_blank" rel="external">顺序一致性</a>的无锁编程。我们要关注的是多核或者多处理器环境下的内存执行顺序。</p>
<p>不幸的是，你会发现Acquire与Release语义甚至比lock-free更难理解。关于这个词，如果你在网上搜索的越多，越会感觉与它的定义更矛盾。 得益于Herb Sutter，Bruce Dawson通过<a href="https://msdn.microsoft.com/en-us/library/windows/desktop/ee418650.aspx" target="_blank" rel="external">white paper</a>提供了一些好的定义。紧密结合C++11原子性背后的原则，我想给出一些我自己的定义。 </p>
<ul>
<li>Acquire语义的性质只能应用于共享内存中的读操作，不管是read-modify-write操作还是普通的读数据。这种操作被认为是read-acquire。 Acquire 语义能阻止read-acquire和它之后的任何读写操作的乱序。</li>
</ul>
<ul>
<li>Release语义的性质只能应用于共享内存中的写操作，而不管是read-modify-write操作还是普通的写操作。这种操作被认为是write-release. Release 语义能阻止write-release和它之前的任何读写操作的乱序。</li>
</ul>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/acquire1.png" alt=""><br><img src="http://7xppf1.com1.z0.glb.clouddn.com/acquire2.png" alt=""><br>只要你能消化上述的概念，就不难知道Acquire与Release 语义可以通过我在上一篇文章中提到的memory barrier类型的组合来实现。Barrier必须放置在read-acquire操作之后与write-release操作之前。[更新：请注意这些barrier在技术上比单个内存操作上对Acquire与Release 语义的需求更加严格，但能达到理想中的效果]</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/acquire3.png" alt=""></p>
<p>有趣的是不管是Acquire还是Release语义都不需要用到一种开销比较昂贵的memory barrier-StoreLoad barrier, 。举个例子，在PowerPC中，lwsync(lightweight sync的简写)指令同时充当LoadLoad barrier, LoadStore barrier和StoreStore barrier三种角色，所以比sync指令(包含了StoreLoad barrier)的开销要昂贵.</p>
<h3 id="显式平台特定的fence指令"><a href="#显式平台特定的fence指令" class="headerlink" title="显式平台特定的fence指令"></a>显式平台特定的fence指令</h3><p>获取期望的memory barrier的一种方式就是发出显式的fence指令。我们以一个例子开始。假设我们在PowerPC平台下写代码，__lwsync()是一种编译器内置函数，能发出lwsync指令。由于lwsync提供了许多种memory barrier，因此我们可以在下面的代码中用它来建立所需的Acquire或者Release语义。在线程1中，对Ready的写操作变成了一个write-release，在线程2中，对Ready的读操作变成了一个read-acquire。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/acquire4.png" alt=""></p>
<p>如果让两个线程都运行，会发现，<code>r1==1</code>可以作为A的值从线程1成功传递到线程2中的确认标志。如此一来，我们可以保证<code>r2==42</code>。在上一篇文章中，我已经针对LoadLoad 和 StoreStore给出了一个很长的类比来阐述其是如何工作的，我在这里就不再解释了。</p>
<p>在正式的定义中，我们说对Ready的写操作与读操作是同步的。在<a href="http://preshing.com/20130823/the-synchronizes-with-relation/" target="_blank" rel="external">这里</a>我对<code>synchronizes-with</code>专门写了一篇文章。目前为止，我们已经可以来说明要让这技术能通用，Acquire与Release 语义必须应用在同一个变量中（在这个例子中是Ready变量），读和写操作必须都是原子操作。在这里，Ready是个简单的已经对齐的整型变量，所以这些读写在PowerPC中就已经是原子操作了<sup>注2</sup>。</p>
<h3 id="在可移植性C-11中使用Fences"><a href="#在可移植性C-11中使用Fences" class="headerlink" title="在可移植性C++11中使用Fences"></a>在可移植性C++11中使用Fences</h3><p>上述的例子是依赖编译器和处理器的。要支持多平台的一种方法就是将代码转化成C++11. 所有的C++11标识符都存在std空间中，所以为了将下面的例子变得简单一些，我们假设<code>using namespace  std;</code>语句提前放在代码的某处了。</p>
<p>C++11的原子库标准定义了一个可移植的函数<code>atomic_thread_fence()</code>，函数采用一个参数来指定fence的类型。这个参数有很多种可能的值，但我们在这里最感兴趣的是<code>memory_order_acquire</code>与<code>memory_order_release</code>. 我们用这个函数来替代__lwsync()</p>
<p>在让这个例子变得更完整之前，还需要作一点修改。在PowerPC平台上，我们知道对Ready变量的两个操作都是原子的，但不是每个平台上都这样。我们可以将Ready变量从整型改为<code>atomic&lt;int&gt;</code>。 考虑到针对对齐的整型，读写操作在现今所有的CPU中都是原子的，我知道这是个傻瓜式的修改。我会在synchronizes-with文章中描述更多关于这方面的内容，现在，我们姑且认为理论上能确保100%的准确率。另外， 不必对A做任何修改。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/acquire5.png" alt=""></p>
<p><code>memory_order_relaxed</code>参数意味着“确保这些操作是原子的，但对那些本身不在那里的操作不作任何的顺序限制或者强加memory barrier”</p>
<p>再说一次，上述的<code>atomic_thread_fence()</code> 调用可以在PowerPC中实现像lwsync一样的效果。类似的，他们都能在ARM上发出dmb指令，这点我相信至少是和在PowerPC平台上能有同样效果的。在X86/X64平台上，<code>atomic_thread_fence()</code>调用可以简单的实现成和compiler barrier一样的效果，因为一般来说，x86/x64上的每个读操作已经包含了Acquire语义，并且每个写操作都包含了Release 语义。这就是为什么x86/x64经常被说成是强内存模型<sup>注3</sup>.</p>
<h3 id="在可移植C-11上不用fences"><a href="#在可移植C-11上不用fences" class="headerlink" title="在可移植C++11上不用fences"></a>在可移植C++11上不用fences</h3><p>在C++11中，只要在对Ready上的操作中指定内存执行顺序的限制，就可以不发出显式的fence指令来达到Acquire与Release语义。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/acquire6.png" alt=""></p>
<p>考虑每个在Ready上的fence指令。[更新:请注意这种形式和使用独立的fences版本是不完全一样的，技术上来说，没有那么严格]。 编译器会发出必要的指令，来取得和memory barrier一样的所需的效果。具体来说，在Itanium上，每个操作都能简单的实现成一个单指令:<code>ld.acq</code> 与 <code>st.rel</code>. 如之前那样，r1 == 1意味着一种<br>synchronizes-with关系，作为对r2 == 42的确认。</p>
<p>在C++11中，这实际上是一种更好的方式来表达Acquire与 Release语义。前面例子中使用的<code>atomic_thread_fence()</code> 函数在标准的制定中是添加的相对较晚的。</p>
<h3 id="Acquire-and-Release-While-Locking"><a href="#Acquire-and-Release-While-Locking" class="headerlink" title="Acquire and Release While Locking"></a>Acquire and Release While Locking</h3><p>如你所见，这篇文章中没有一个例子能利用Acquire与Release 语义提供的LoadStore barrier优势。 实际上，只有LoadLoad和StoreStore 就足矣。这就是为什么在这篇文章中，我选一个简单的列子来让我们能集中关注API和语义。</p>
<p>必须用到LoadStore一个例子是当使用Acquire与 Release语义来实现(mutex) 锁。<br>实际上，这就是名字的由来: 获取一个锁意味着Acquire 语义，释放锁意味着Release语义。 之间所有的内存操作都包含在了一个小的barrier的三明治中，用来阻止任何要跨越界限的内存乱序。</p>
<h2 id="译者注"><a href="#译者注" class="headerlink" title="译者注"></a>译者注</h2><p>注1:lock free虽然翻译为无锁，但是它并不是“没有锁”的意思，“没有锁”在英文里一般是lockless。lock free考察的是若干个线程组成的系统，不管如何，总能保证至少有一个线程能make progress，因此保证系统，从整体上看，是make progress的。这样的系统或者算法实现就是lock free的。</p>
<p>注2:在X86体系结构下，对于64位架构，只要同时满足以下两个条件，那么对该基础内置数据类型变量（int、bool、指针等）的普通读写都是原子的：</p>
<p>条件1:该变量按cache line对齐</p>
<p>条件2:该变量sizeof值不超过64</p>
<p>所以，要注意的是，32位cpu和系统中，即使64位例如int64_t类型变量即使是对齐也不保证是原子的。这种情况可以使用<code>__sync_fech_and_add</code>等gcc提供的内置原子操作。</p>
<p>注3:即使这样，读者诸君还是得注意，虽然store自带release语义，load自带acquire语义，但是X86还是会对写读不同变量进行乱序。（当然，这点和release 、acquire语义不矛盾）。为什么不矛盾？因为</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> t = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span> c = a;</span><br></pre></td></tr></table></figure>
<p>这里是写变量t，读另外一个变量a，因此可能乱序。但是不矛盾。因为写t提供release语义是说它之前的代码不会和它乱序，却没有保证它之后的代码不和它乱序；同理，对于读a提供acquire语义，只保证它之后的代码不会和它乱序，却没有保证它之前的代码不和它乱序。这里的之前之后都是针对program order，也请读者诸君务必注意理解。</p>
<p>注4:一般说来，锁要提供三种语义：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">b++;</span><br><span class="line">lock.lock();</span><br><span class="line">a++;</span><br><span class="line">d++;</span><br><span class="line">lock.unlock();</span><br><span class="line">c++;</span><br></pre></td></tr></table></figure>
<p>语义1:当线程1更新完a(也包括d)的值之后释放锁，线程2进入临界区必须读到a(也包括d)的新值，也就是线程1更新完之后的值。可以认为是acquire release或者happen before语义。</p>
<p>语义2:同一时刻，<code>a++</code>这条语句只能有一个线程在执行。可以认为是临界语义或者互斥语义。</p>
<p>语义3:必须保证a++不会被乱序到b++处执行，也不能乱序到c++处执行。这个自然也是临界语义或者互斥语义的一部分，因为如果乱序，那么无临界区可言了。但是读者诸君要注意到，以下这样的乱序是完全可以的、合法的：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">b++;</span><br><span class="line">lock.lock();</span><br><span class="line">d++;</span><br><span class="line">a++;</span><br><span class="line">lock.unlock();</span><br><span class="line">c++;</span><br></pre></td></tr></table></figure>
<p>或者：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lock.lock();</span><br><span class="line">b++;</span><br><span class="line">a++;</span><br><span class="line">d++;</span><br><span class="line">c++;</span><br><span class="line">lock.unlock();</span><br></pre></td></tr></table></figure>
<h3 id="Acknowledgement"><a href="#Acknowledgement" class="headerlink" title="Acknowledgement"></a>Acknowledgement</h3><p>本文由 <a href="http://weibo.com/2767520802/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="external">Diting0x</a> 与 <a href="http://weibo.com/yebangyu" target="_blank" rel="external">睡眼惺忪的小叶先森</a> 共同完成，在原文的基础上添加了许多精华注释，帮助大家理解。</p>
<p>感谢好友<a href="http://weibo.com/u/1707881862?topnav=1&amp;wvr=6&amp;topsug=1&amp;is_all=1" target="_blank" rel="external">小伙伴-小伙伴儿 </a>阅读了初稿，并给出宝贵的意见。</p>
<p>原文： <a href="http://preshing.com/20120913/acquire-and-release-semantics/" target="_blank" rel="external">http://preshing.com/20120913/acquire-and-release-semantics/</a></p>
<p>本文遵守Attribution-NonCommercial-NoDerivatives 4.0 International License (CC BY-NC-ND 4.0)<br>仅为学习使用，未经博主同意，请勿转载<br>本系列文章已经获得了原作者preshing的授权。版权归原作者和本网站共同所有</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一般来说，在无锁(lock-free)&lt;sup&gt;注1&lt;/sup&gt;编程中，线程有两种方法来操作共享内存：线程间相互竞争一种资源或者相互合作传递消息。Acquire与Release语义对后者来说很关键：保证在线程间可靠地相互传递消息。实际上，我大胆地猜测，不正确的或者缺乏Acquire与Release语义是导致无锁编程产生错误的最常见 原因。&lt;/p&gt;
    
    </summary>
    
      <category term="High-performance" scheme="http://yoursite.com/categories/High-performance/"/>
    
    
  </entry>
  
  <entry>
    <title>深入探索并发编程系列(七)-内存屏障:资源控制操作</title>
    <link href="http://yoursite.com/blog/2016/09/19/sourcecontrol/"/>
    <id>http://yoursite.com/blog/2016/09/19/sourcecontrol/</id>
    <published>2016-09-19T05:16:57.000Z</published>
    <updated>2017-02-09T13:03:19.000Z</updated>
    
    <content type="html"><![CDATA[<p>当你使用资源控制时, 那么你肯定在试图理解内存执行顺序。不管你是用C,C++还是其它语言，这都是在编写无锁(lock-free)代码时需要重点考虑的。</p>
<a id="more"></a>
<p>在上一篇文章中，我们介绍了<a href="http://www.chongh.wiki/blog/2016/09/05/compilermemoryreorder/" target="_blank" rel="external">编译期间的内存乱序</a>，这一部分内容构成内存执行顺序问题的一部分。这篇文章讲述另一部分：处理器本身在运行期间的内存执行顺序。与编译器乱序一样，处理器乱序对于单线程来说也是不可见的。只有在使用无锁(lock-free)技术时-也就是说，当共享内存在线程之间不是互斥量时，乱序现象才会变得显露无疑。然而，与编译器乱序不同的是，<a href="http://www.chongh.wiki/blog/2016/08/11/memoryreorder/" target="_blank" rel="external">处理器乱序只在多核和多处理器系统中才可见</a>.</p>
<p>你可以使用任意能充当memory barrier的指令来确保执行正确的内存顺序。某种程度上来说，这是你需要了解的唯一技术，因为当你使用这类指令时，能自动处理好编译器执行顺序问题。充当memory barrier的指令包括(但不局限于)以下情况<sup>注1</sup>：</p>
<blockquote>
<ul>
<li>GCC中的内联汇编指令，比如PowerPC平台下的 asm volatile(“lwsync” ::: “memory”)</li>
<li>除Xbox 360平台以外，任意的Win32 Interlocked操作，</li>
<li>C++11原子类型操作，比如load(std::memory_order_acquire)</li>
<li>POSIX 互斥量操作，比如 pthread_mutex_lock</li>
</ul>
</blockquote>
<p>正因为有许多指令可以充当memory barrier，我们需要去了解许多不同类型的memory barrier. 实际上，上述的所有指令产生的memory barrier都属于不同类型，这会写lock-free代码时给你带来困惑。为了试图把事情说清楚，我会把那些有助于理解大部分(但不是全部)可能的memory barrier类型做一个类比。</p>
<p>首先，考虑一种典型的多核系统结构。双核，每个核上有32KiB的L1数据缓存，两个核之间有1MiB的L2共享缓存, 主内存512MiB<sup>注2</sup>.</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/sourcecontrol1.png" alt=""></p>
<p>多核系统就有点像是一群程序员通过一种怪异的资源控制策略来合作一个项目。举个例子，上面的双核系统对应两个程序员合作的场景。将这两个程序员分别取名为Larry与Sergey.</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/sourcecontrol2.png" alt=""></p>
<p>右边有个共享的中心仓库-代表主内存和共享L2缓存的结合体。Larry和Sergey在本地机器中都有仓库的工作副本，分别是每个CPU核中的L1缓存。每台机器上有个临时存储区，用来记录寄存器和本地变量的值。现在两个程序员坐在那里，富有激情的编辑他们的工作副本和临时存储区，根据他们看见的数据决定下一步该做什么–就像是一个线程就在那个CPU核上工作一样。</p>
<p>在这开始引入资源控制策略。在这个类比里，资源控制策略实际上是非常奇怪的。由于Larry和Sergey修改了仓库的工作副本，他们的修改在背后不断地从仓库中来回传播(leaking)，这种情况发生的次数都是随机的。只要larry编辑文件X，对文件的修改都会泄露到仓库中，但不能保证什么时候才会发生。有可能会立即发生，有可能会发生很多次，也有可能之后才发生。这时，他可能会继续编辑其它的文件，比如Y和Z，这些改变可能会在X泄露之前就已经传播了。这样一来，写操作在写进仓库的过程中就很容易发生乱序。</p>
<p>类似的，在Sergey的机器上，不能保证那些修改从仓库到工作副本中来回传播的时间间隔和顺序。这样一来，从仓库读数据的过程中就很容易发生乱序。</p>
<p>现在，如果每个程序员分别独自工作在仓库的隔离区域，他们都不会意识到背后的传播过程，甚至不知道另一个程序员的存在。这就好比两个正在运行的独立的单线程。在这个例子中，内存执行顺序的<a href="http://www.chongh.wiki/blog/2016/09/05/compilermemoryreorder/" target="_blank" rel="external">基本原则</a>还是能保证的。</p>
<p>当程序员开始在仓库的同一区域工作时，上述的类比就显得更加重要了。再来看看<a href="http://www.chongh.wiki/blog/2016/08/11/memoryreorder/" target="_blank" rel="external">之前文章</a>中的例子。 X和Y是全局变量，且都初始化为0.</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/sourcecontrol3.png" alt=""></p>
<p>把X和Y想象成是Larry的工作副本，Sergey的工作副本以及仓库本身中的文件。Larry将1写入工作副本中的X，sergey同时将1写进工作副本中的Y。 在查找其它副本之前, 如果修改没有回传到创库.(leak to..) 而且 没有返回到对应的副本(back). 结果就是r1=0 r2=0<br>。起初可能会觉得这种结果与直觉上相反，但对照下资源控制的类比方式，就觉得很明显了。<br><img src="http://7xppf1.com1.z0.glb.clouddn.com/sourcecontrol4.png" alt=""></p>
<h2 id="Memory-Barrier类型"><a href="#Memory-Barrier类型" class="headerlink" title="Memory Barrier类型"></a>Memory Barrier类型</h2><p>幸运的是，Larry和Sergey不完全是对这种随机性与在背后发生的不可预计的传播无能为力。他们能发出一些特殊指令，调用fence指令来充当memory barrier）. 对于上述类比方式，可以定义四种memory barrier，因此也对应四种fence指令。每种memory barrier都是以阻止不同类型的内存乱序能力来命名，比如，StoreLoad用来阻止写读类型。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/sourcecontrol5.png" alt=""></p>
<p>就像<a href="http://g.oswego.edu/dl/jmm/cookbook.html" target="_blank" rel="external">Doug</a>指出的那样，这四种类型可能并不能很好的对应真实CPU中的特殊指令。大部分情况，一条CPU指令能充当上述几种memory barrier类型的组合，可能也会附带一些其它的效果。不论在什么情况下，只要你以资源控制的类比方式理解了这四种memory barrier，就容易理解真实CPU中的大多数的指令与一些高级编程语言的构造。</p>
<h3 id="LoadLoad"><a href="#LoadLoad" class="headerlink" title="LoadLoad"></a>LoadLoad</h3><p>一个LoadLoad barrier能有效地阻止在barrier之前执行的读与在barrier之后执行的读造成的乱序。</p>
<p>在我们的类比中，LoadLoad fence 指令基本等价于仓库的的pull操作。想象git pull, hg pull, p4 sync, svn update 或者cvs update， 所有操作都在仓库工作。如果本地的修改有任何的merge冲突，我们就说他们被随机的决议(resolved)。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/sourcecontrol6.png" alt=""></p>
<p>要提醒你的是，不能保证LoadLoad会pull整个仓库的最近(或HEAD)的修订版本。只要HEAD版本至少是从中心仓库传播到本地机器的最新值，就能pull比HEAD版本更老的版本。</p>
<p>这听起来可能像一个较弱的保证，但仍然是一个完美的方案来阻止读取过时的数据。考虑一个经典的例子，Sergey检查共享flag来看Larry是不是发布了一些数据。如果flag为真，在读取发布的数据之前，Sergey发出一个LoadLoad barrier 。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (IsPublished)                   <span class="comment">// Load and check shared flag</span></span><br><span class="line">&#123;</span><br><span class="line">    LOADLOAD_FENCE();              <span class="comment">// Prevent reordering of loads</span></span><br><span class="line">    return Value;                  <span class="comment">// Load published value</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>显然，这个例子依赖于IsPublished标志位是否传播到了Sergey的工作副本。不用去关心这些是什么时候发生的。只要发现了传播的flag，它就发出一个LOadLoad fence来阻止读取Value的值（这个值比flag本身还要老).</p>
<h3 id="StoreStore"><a href="#StoreStore" class="headerlink" title="StoreStore"></a>StoreStore</h3><p>一个StoreStore barrier能有效的阻止在barrier之前的写操作与在barrier之后的写操作之间的乱序。</p>
<p>在我们的类比中，StoreStore fence指令对应仓库的push操作。想象git push, hg push, p4 submit, svn commit or cvs commit 都发生在整个仓库中。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/sourcecontrol7.png" alt=""></p>
<p>跟绕口令一样,假设StoreStore指令不是即时的，而是以异步的方式延后执行。因此，尽管Larry执行了StoreStore指令，我们对于他之前所有的写操作什么时候能再在仓库中出现不能做任何的假设。</p>
<p>这听起来可能也像是弱的保证，但是，已经足够来阻止Sergey收到Larry发布的任何过时的数据。 回到上面同样的例子， 这时Larry只需要发布一些数据到共享内存，发出一个 StoreStore barrier，然后将共享flag设置为true</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Value = x;                         <span class="comment">// Publish some data</span></span><br><span class="line">STORESTORE_FENCE();</span><br><span class="line">IsPublished = <span class="number">1</span>;                   <span class="comment">// Set shared flag to indicate availability of data</span></span><br></pre></td></tr></table></figure>
<p>再说一次，我们依赖从Larry的工作副本中传播到Sergey的Ispublished值. 一旦Sergey检测到，他相信自己看到了Value的正确值。有趣的是，在这种工作模式中，Value不用是原子类型，也可以是有许多元素的大结构体。</p>
<h3 id="LoadStore"><a href="#LoadStore" class="headerlink" title="LoadStore"></a>LoadStore</h3><p>不像LoadLoad和StoreStore，就资源控制操作来看，LoadStore没有比较合适的类比。 理解LoadStore的最好方法很简单，就是考虑指令乱序。</p>
<p>想象Larry有一系列指令要执行。某些指令让他从自己的工作副本读取数据到寄存器中，以及某些指令从寄存器中写数据到工作副本中。Larry具备欺骗指令的能力，但只限于一些特殊场合。只要他遇到读操作时，他就会先检测读操作之后的任何写操作。如果写操作和当前的读操作完全不相关，他会先略过读操作，先进行写操作，结束后在进行读操作。在这种场景下，内存执行顺序的基本原则–绝不修改单程序的行为–仍然是遵守了的。</p>
<p>对于真实CPU，如果某些处理器中有一个缓存错过了读操作(紧接着缓存命中的写操作)，这种指令乱序就可能会发生。为了理解这个类比，硬件细节并不重要。我们只当做Larry的工作很繁琐，而这正是他能创新的机会（这种机会很有限)。 不管他是否选择这么做都是完全不可预计的。幸运的是，阻止这种乱序类型的开销并不大。当Larry遇到一个LoadStore barrier, 他就能简单的避免barrier附近的乱序。</p>
<p>在我们的类比中，尽管在读写之间有个LoadLoad或者StoreStore barrier时，Larry执行这种类型的LoadStore乱序也是有效的。 然而，在真实的CPU中，充当LoadStore barrier的指令至少能充当其它两种类型的barrier。</p>
<h3 id="StoreLoad"><a href="#StoreLoad" class="headerlink" title="StoreLoad"></a>StoreLoad</h3><p>StoreLoad barrier能确保其它处理器遇到barrier之前执行所有的写操作，另外，barrier之后执行的所有读操作能收到最近能被barrier可见的值。 .换句话说，它能在barrier处理所有的读操作之前有效地阻止所有的写操作乱序，尊重顺序一致性多处理器执行那些操作的方式。</p>
<p>StoreLoad是唯一的。这是唯一的一种memory barrier类型可以阻止<a href="http://www.chongh.wiki/blog/2016/08/11/memoryreorder/" target="_blank" rel="external">前文</a>提到的这种结果：r1 = r2 = 0，这个例子我在前面的文章中提到过很多次了。</p>
<p>如果你一路仔细地读下来，可能会有个疑惑： StoreLoad和 StoreStore再紧接着一个LoadLoad有什么不一样呢？毕竟，StoreStore 将修改push到仓库中，然而LoadLoad 把远程的修改pull回来。然而，那两种barrier类型是不够的。记住，push操作可能会因为任意数量的指令而延迟， pull操作可能不会从HEAD版本中pull数据。 这也解释了为什么owerPC的lwsync指令–充当所有LoadLoad, LoadStore和StoreStore memory barrier,但不是StoreLoad–是不足够来阻止例子中的r1 = r2 = 0 这种结果的。</p>
<p>拿类比来说，StoreLoad barrier能通过push所有局部修改到仓库中来实现，等待那个操作完成，然后pull 仓库中绝对的、最近的主干修订版本。在大部分处理器上，充当StoreLoad barrier的指令比充当其它类型barrier的指令开销更大。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/sourcecontrol8.png" alt=""></p>
<p>如果在那个操作中放置一个LoadStore barrier,也没什么大不了的, 之后我们得到的是一个完整的memory fence–一次性充当所有四种barrier 类型。 正如<a href="http://g.oswego.edu/dl/jmm/cookbook.html" target="_blank" rel="external">Doug</a>指出的那样，在目前所有处理器上都是这样，每个充当StoreLoad barrier的指令也充当完整的memory fence.</p>
<h2 id="类比给你带来了什么？"><a href="#类比给你带来了什么？" class="headerlink" title="类比给你带来了什么？"></a>类比给你带来了什么？</h2><p>正如我之前提到的那样，在处理内存执行顺序时，每个处理器都有不同的<a href="http://preshing.com/20120612/an-introduction-to-lock-free-programming/" target="_blank" rel="external">特点</a>。具体来说，在x86/64家族中有一种强内存模型。这是为了让内存乱序的发生降到最低。PowerPC和ARM有着弱的内存模型。Alpha因自成一派而出名。幸运的是，这篇文章的类比对应一种弱的<a href="http://preshing.com/20120930/weak-vs-strong-memory-models/" target="_blank" rel="external">内存模型</a>。 如果你能用心对待它，并使用这里提供的fence指令来实施正确的内存执行顺序，你就能处理大部分的CPU。</p>
<p>这种类比同样对应针对C++11和C11的抽象机器。因此，如果你使用那些语言的标准库写无锁(lock-free)代码，同时将上述的类比记在脑里，就更有可能在任何平台下正确执行。</p>
<p>在这种类比中，我说过，每个程序员代表在一个核心中正在运行的单线程。在一个真实的操作系统中，线程更倾向在生命周期中在不同的核心里移动，这时上述的类比仍然有效。我也在机器语言和C/C++语言不断变换来举例。显然，我们更倾向使用C/C++，或者另外更高级的语言。这是有可能的，因为任何充当memory barrier的操作也能阻止编译器乱序。</p>
<p>我还没有写关于每种memory barrier类型的文章。例如，也存在数据依赖(data dependency )barriers<sup>注3</sup>。 我会在以后的文章中讲这些内容。然而，上面给出的四种类型仍是最重要的。</p>
<p>如果你对CPU在底层是如何工作的很感兴趣–像写缓存，缓存一致性协议(cache coherency protocol)以及硬件实施细节相关的东西–以及它们为什么会发生内存乱序<sup>注4</sup>，我推荐Paul McKenney &amp; David Howell的<a href="https://www.kernel.org/doc/Documentation/memory-barriers.txt" target="_blank" rel="external">工作</a>。 实际上，我认为能成功写好无锁(lock-free)代码的大部分程序员都至少都对这种硬件细节有点熟悉。</p>
<h2 id="译者注"><a href="#译者注" class="headerlink" title="译者注"></a>译者注</h2><p>注1：gcc+x86下，编译器级别的memory barrier和CPU级别的memory barrier可以如下实现：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">define <span class="title">COMPILER_BARRIER</span><span class="params">()</span> __asm__ __<span class="title">volatile__</span><span class="params">(<span class="string">""</span> : : : <span class="string">"memory"</span>)</span></span><br><span class="line">define <span class="title">CPU_BARRIER</span><span class="params">()</span> __sync_synchronize</span></span><br></pre></td></tr></table></figure></p>
<p>其中，<code>CPU_BARRIER()</code>可以防止CPU写读、写写、读写、读读乱序。如你所知，CPU级别的memory barrier同时约束CPU和编译器的乱序；而编译器级别的memory barrier只约束编译器的乱序，不影响CPU。</p>
<p>注2：现在用的很多的cpu一般有三级cache。</p>
<p>注3：为了演示data dependency barrier，考虑以下例子：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">初始化</span><br><span class="line"><span class="keyword">int</span> A = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span> B = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">int</span> C = <span class="number">3</span>;</span><br><span class="line"><span class="keyword">int</span> *P = &amp;A;</span><br><span class="line"><span class="keyword">int</span> *Q = &amp;B;</span><br><span class="line"><span class="comment">//cpu1</span></span><br><span class="line">B = <span class="number">4</span>;</span><br><span class="line">CPU_BARRIER();</span><br><span class="line">P = &amp;B;</span><br><span class="line"><span class="comment">//cpu2</span></span><br><span class="line">Q = P;</span><br><span class="line">D = *Q</span><br></pre></td></tr></table></figure>
<p>从直觉上说，Q最后要么等于&amp;A，要么等于&amp;B。也就是说：</p>
<p>Q == &amp;A， D == 1 </p>
<p>或者</p>
<p>Q == &amp;B， D == 4  </p>
<p>但是，让人吃惊的是，在某些CPU体系结构例如DEC Alpha下，可能出现</p>
<p>Q == &amp;B， D == 2的情形，原因是，虽然CPU1按照顺序执行完两条语句先后对B和P进行了修改，但CPU2可能先感知到P的变化，读到了P的新值，然后才是B的新值。因此，为了防止这样的问题，需要加一个data dependency barrier。</p>
<p>注4：为什么CPU乱序只在多核多线程下才可能会暴露出问题？为什么X86体系结构的Intel CPU要对写读进行乱序？</p>
<p>要明白这两个问题，我们首先得知道cache coherency，也就是所谓的cache一致性。</p>
<p>在现代计算机里，一般包含至少三种角色：cpu、cache、内存。一般说来，内存只有一个；CPU Core有多个；cache有多级，cache的基本块单位是cacheline，大小一般是64B-256B。</p>
<p>每个cpu core有自己的私有的cache(有一级cache是共享的，如文中所示)，而cache只是内存的副本。那么这就带来一个问题：如何保证每个cpu core中的cache是一致的？</p>
<p>在广泛使用的cache一致性协议即MESI协议中，cacheline有四种状态：Modified、Exclusive、Shared、Invalid，分别表示修改、独占、共享、无效。</p>
<p>当某个cpu core写一个内存变量时，往往是（先）只修改cache，那么这就会导致不一致。为了保证一致，需要先把其他core的对应的cacheline都invalid掉，给其他core们发送invalid消息，然后等待它们的response。</p>
<p>这个过程是耗时的，需要执行写变量的core等待，阻塞了它后面的操作。为了解决这个问题，cpu core往往有自己专属的store buffer。</p>
<p>等待其他core给它response的时候，就可以先写store buffer，然后继续后面的读操作，对外表现就是写读乱序。</p>
<p>因为写操作是写到store buffer中的，而store buffer是私有的，对其他core是透明的，core1无法访问core2的store buffer。因此其他core读不到这样的修改。</p>
<p>这就是大概的原理。MESI协议非常复杂，背后的技术也很有意思。</p>
<h3 id="Acknowledgement"><a href="#Acknowledgement" class="headerlink" title="Acknowledgement"></a>Acknowledgement</h3><p>本文由 <a href="http://weibo.com/2767520802/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="external">Diting0x</a> 与 <a href="http://weibo.com/yebangyu" target="_blank" rel="external">睡眼惺忪的小叶先森</a> 共同完成，在原文的基础上添加了许多精华注释，帮助大家理解。</p>
<p>感谢好友<a href="http://weibo.com/u/1707881862?topnav=1&amp;wvr=6&amp;topsug=1&amp;is_all=1" target="_blank" rel="external">小伙伴-小伙伴儿 </a>阅读了初稿，并给出宝贵的意见。</p>
<p>原文:<a href="http://preshing.com/20120710/memory-barriers-are-like-source-control-operations/" target="_blank" rel="external">http://preshing.com/20120710/memory-barriers-are-like-source-control-operations/</a></p>
<p>本文遵守Attribution-NonCommercial-NoDerivatives 4.0 International License (CC BY-NC-ND 4.0)<br>仅为学习使用，未经博主同意，请勿转载<br>本系列文章已经获得了原作者preshing的授权。版权归原作者和本网站共同所有</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;当你使用资源控制时, 那么你肯定在试图理解内存执行顺序。不管你是用C,C++还是其它语言，这都是在编写无锁(lock-free)代码时需要重点考虑的。&lt;/p&gt;
    
    </summary>
    
      <category term="High-performance" scheme="http://yoursite.com/categories/High-performance/"/>
    
    
  </entry>
  
  <entry>
    <title>深入探索并发编程系列(六)-编译期间内存乱序</title>
    <link href="http://yoursite.com/blog/2016/09/05/compilermemoryreorder/"/>
    <id>http://yoursite.com/blog/2016/09/05/compilermemoryreorder/</id>
    <published>2016-09-05T09:44:17.000Z</published>
    <updated>2016-11-01T16:59:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>写在最前：掌握并发编程非常困难，除了多读书、多写代码、多调试、多和朋友讨论，别无他法。<br><a id="more"></a><br>在众多资料中，preshing这个博客质量很高，经过和作者邮件沟通获得授权后，我们着手翻译了他的一系列文章并加上注释，构成了“深入探索并发编程系列”。翻译，力求精准又易懂；注释，力求全面又有益，希望对大家理解这个系列有所帮助，也希望可以为社区做点贡献。</p>
<hr>
<p>在写完C/C++代码之后与CPU执行之前，代码会根据一定规则在与内存的交互过程中发生乱序。内存执行顺序的变化在编译器(编译期间)和cpu(运行期间)中都会发生，其目的都是为了让代码运行的更快。</p>
<p>编译器开发者和cpu厂商都遵守着内存乱序的基本原则，简单归纳如下：</p>
<pre><code>不能改变单线程程序的行为
</code></pre><p>这条原则带来的影响就是，写单线程代码的程序员都忽视了内存乱序的影响。在多线程编程中，由于互斥量，信号量和事件都在设计的时候都阻止了它们调用点中的内存乱序，内存乱序的影响同样被忽视了。只有当使用无锁(lock-free)<sup>注1</sup>技术时–内存在线程间共享而没有任何的互斥量-<a href="http://www.chongh.wiki/blog/2016/08/11/memoryreorder/" target="_blank" rel="external">内存乱序的效果</a>才会显露无疑.</p>
<p>要提醒你的是，在多核平台下写lock-free的代码而不发生内存乱序也是有可能的。就像我在<a href="http://preshing.com/20120612/an-introduction-to-lock-free-programming/" target="_blank" rel="external">无锁编程介绍</a>中提到的那样，可以利用顺序一致类型来达到目的(比如java中的volatile变量或C++11原子类型)，这样做的后果是有可能会牺牲一些性能。我不去详细谈论这些细节。在这篇文章中，集中关注编译器对常规，非顺序一致类型的内存乱序情况。</p>
<h3 id="编译器指令乱序"><a href="#编译器指令乱序" class="headerlink" title="编译器指令乱序"></a>编译器指令乱序</h3><p>就像你了解的那样,编译器的工作就是将人们可读的源代码转化为CPU可读的机器码。在转换过程中，编译器是可以非常自由的改变其中行为的。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/compilerreorder1.png" alt=""></p>
<p>其中一个例子就是可以让指令乱序-再次说明，仅仅在单线程程序的行为不会改变的这一基本原则下才有效。<br>这种指令乱序现象主要发生在编译器优化开启的情况下。看看下面的函数</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> A, B;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span></span><br><span class="line"></span>&#123;</span><br><span class="line">    A = B + <span class="number">1</span>;</span><br><span class="line">    B = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果使用GCC 4.6.1编译这个函数而没有开启编译器优化选项时，会产生以下机器代码，使用-s选项可以看到其中的汇编代码。对变量B的写操作恰好发生在对变量A写操作之后，这和源代码中的行为是一致的。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ gcc -S -masm=intel foo.c</span><br><span class="line">$ cat foo.s</span><br><span class="line">        ...</span><br><span class="line">        mov     eax, DWORD PTR _B  (redo this at home...)</span><br><span class="line">        add     eax, <span class="number">1</span></span><br><span class="line">        mov     DWORD PTR _A, eax</span><br><span class="line">        mov     DWORD PTR _B, <span class="number">0</span></span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>
<p>当使用-o2开启编译器优化选项时，结果是这样的：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ gcc -O2 -S -masm=intel foo.c</span><br><span class="line">$ cat foo.s</span><br><span class="line">        ...</span><br><span class="line">        mov     eax, DWORD PTR B</span><br><span class="line">        mov     DWORD PTR B, <span class="number">0</span></span><br><span class="line">        add     eax, <span class="number">1</span></span><br><span class="line">        mov     DWORD PTR A, eax</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>
<p>这时，编译器就有选择的余地了，内存会发生乱序，在写变量A之前会先写变量B。有什么理由不这么做呢？这时内存乱序的基本规则并没有被打破。对于一个单线程程序来说，并不会发觉其中的差异<sup>注2</sup>。</p>
<p>另一方面，在写lock-free代码时,这种编译器导致的乱序行为会引起一些问题。下面是一个经常被引用的例子，共享标志用来指示一些其它的共享数据被published了：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> Value;</span><br><span class="line"><span class="keyword">int</span> IsPublished = <span class="number">0</span>;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sendValue</span><span class="params">(<span class="keyword">int</span> x)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">    Value = x;</span><br><span class="line">    IsPublished = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>想象一下当编译器在对Value进行写操作之前，先写IsPublished变量发生乱序会是什么情况。即使是在单处理器程序中，我们也会遇到一个问题：操作系统以抢占式方式调度某个线程在两次写操作之间运行，这时让其它线程以为Value变量已经更新过了，而实际上并没有。</p>
<p>当然，编译器可能并不会将那些操作乱序，产生的机器代码在任何的多核CPU中（比如x86/x64)或者在任何CPU类型的单核处理器中，都会像lock-free方式一样工作，这个属于<a href="http://preshing.com/20120930/weak-vs-strong-memory-models/" target="_blank" rel="external">强内存模型</a><br>如果正好就在那样的环境中工作，只能说我们是幸运的。毫无疑问，识别共享变量的内存乱序一定要多练习，并且要确保内存执行顺序能正确实施，如你所愿。</p>
<h3 id="显式Compiler-Barriers"><a href="#显式Compiler-Barriers" class="headerlink" title="显式Compiler Barriers"></a>显式Compiler Barriers</h3><p>阻止编译器级别的内存乱序最简单方式就是使用一种比较特殊的直接方法，称作compiler barrier. 我已经在前面的文章中介绍了GCC的compiler barrier. 在Microsoft Visual C++中，_ReadWriteBarrier充当同样的角色。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> A, B;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span></span><br><span class="line"></span>&#123;</span><br><span class="line">    A = B + <span class="number">1</span>;</span><br><span class="line">    <span class="function"><span class="keyword">asm</span> <span class="title">volatile</span><span class="params">(<span class="string">""</span> ::: <span class="string">"memory"</span>)</span></span>;</span><br><span class="line">    B = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样修改之后，我们可以开启编译器优化，内存的写指令会保证你想要的执行顺序</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ gcc -O2 -S -masm=intel foo.c</span><br><span class="line">$ cat foo.s</span><br><span class="line">        ...</span><br><span class="line">        mov     eax, DWORD PTR _B</span><br><span class="line">        add     eax, <span class="number">1</span></span><br><span class="line">        mov     DWORD PTR _A, eax</span><br><span class="line">        mov     DWORD PTR _B, <span class="number">0</span></span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>
<p>类似的，如果我们想保证sendMessage例子的正确性，并且只关心单核处理器系统，那么这里也需要引入compiler barrier. 不仅sending操作需要compiler barrier来阻止写操作乱序，接收端在读操作之间同样需要。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> COMPILER_BARRIER() asm volatile(<span class="string">""</span> ::: <span class="string">"memory"</span>)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> Value;</span><br><span class="line"><span class="keyword">int</span> IsPublished = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sendValue</span><span class="params">(<span class="keyword">int</span> x)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">    Value = x;</span><br><span class="line">    COMPILER_BARRIER();          <span class="comment">// prevent reordering of stores</span></span><br><span class="line">    IsPublished = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">tryRecvValue</span><span class="params">()</span></span><br><span class="line"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (IsPublished)</span><br><span class="line">    &#123;</span><br><span class="line">        COMPILER_BARRIER();      <span class="comment">// prevent reordering of loads</span></span><br><span class="line">        return Value;</span><br><span class="line">    &#125;</span><br><span class="line">    return <span class="number">-1</span>;  <span class="comment">// or some other value to mean not yet received</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>就像我提到的那样，compiler barrier在单核处理器中已经足够能用来阻止内存乱序了。但现在已经是2012年了，更常见的是多核处理器。如果我们要保证交互在多处理器环境中依然能保证想要的执行顺序，并且能适用任意的CPU架构，仅仅compiler barrier是不够的。这时我们需要一个CPU fence指令，或者在运行时能执行充当memory barrier的操作<sup>注3</sup>。我会在<a href="http://preshing.com/20120710/memory-barriers-are-like-source-control-operations/" target="_blank" rel="external">下面文章</a>中介绍更多这方面的内容.</p>
<p>Linux内核的预处理器宏(比如smb_rmb)可以充当CPU fence指令，这些宏在单核处理器系统中编译时被降级为简单的 compiler barriers<sup>注4</sup>.</p>
<h3 id="隐式Compiler-Barrier"><a href="#隐式Compiler-Barrier" class="headerlink" title="隐式Compiler Barrier"></a>隐式Compiler Barrier</h3><p>也有其它的方法来阻止编译器乱序。当然，上面提到的CPU fence指令就能直接作为compiler barriers. 下面是PowerPC系统中CPU fence指令的例子，它在GCC中被定义为一个宏：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> RELEASE_FENCE() asm volatile(<span class="string">"lwsync"</span> ::: <span class="string">"memory"</span>)</span></span><br></pre></td></tr></table></figure>
<p>我们可以在代码中任意位置放置RELEASE_FENSE,来阻止处理器乱序以及编译器乱序。举个例子，在多处理器环境下，它可以让sendValue函数变得更加安全。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sendValue</span><span class="params">(<span class="keyword">int</span> x)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">    Value = x;</span><br><span class="line">    RELEASE_FENCE();</span><br><span class="line">    IsPublished = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在新的C++11原子库标准中，如果一个原子操作不是使用std::memory_order_relaxed这种内存序选项<sup>注5</sup>，那么它也可以作为一个compiler barrier</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> Value;</span><br><span class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">int</span>&gt; IsPublished(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sendValue</span><span class="params">(<span class="keyword">int</span> x)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">    Value = x;</span><br><span class="line">    <span class="comment">// &lt;-- reordering is prevented here!</span></span><br><span class="line">    IsPublished.store(<span class="number">1</span>, <span class="built_in">std</span>::memory_order_release);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>和你想的那样，每个包含compiler barrier的函数自身都可以作为一个compiler barrier，这个函数也可以是内联的。(然而，微软的文档中表明Visual C++ 编译器的早期版本并不是那么回事)</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">doSomeStuff</span><span class="params">(Foo* foo)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">    foo-&gt;bar = <span class="number">5</span>;</span><br><span class="line">    sendValue(<span class="number">123</span>);       <span class="comment">// prevents reordering of neighboring assignments</span></span><br><span class="line">    foo-&gt;bar2 = foo-&gt;bar;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实际上，大多数的函数调用不管它们自身是否包含compiler barrier,都可以充当compiler barrier. 这里排除那些内联函数<sup>注6</sup>，用pure属性声明的函数<sup>注7</sup>，以及开启了link-time code generation编译链接选项的情况<sup>注8</sup>。除了上述这些情况，由于编译器并不清楚函数的副作用，对一个外部函数的调用比compiler barrier还要强。编译器必须要放弃那些对此函数可见的内存上的任何假设。</p>
<p>当你能考虑到这些的时候，就可以高枕无忧了。在上面的代码中，假设sendValue函数在一个外部库里实现。编译器是怎么知道sendValue不依赖于foo-&gt;bar的值呢？它又是如何知道sendValue不会在内存中修改foo-&gt;bar呢？它并不知道。因此，为了遵守内存执行顺序的基本原则，编译器不能对sendValue函数的外部调用做任何乱序操作。类似地，它必须在调用结束后在内存中读取foo-&gt;bar的新值，而不是假设它仍然是5，尽管这时已经开启了优化选项。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ gcc -O2 -S -masm=intel dosomestuff.c</span><br><span class="line">$ cat dosomestuff.s</span><br><span class="line">        ...</span><br><span class="line">        mov    ebx, DWORD PTR [esp+<span class="number">32</span>]</span><br><span class="line">        mov    DWORD PTR [ebx], <span class="number">5</span>            <span class="comment">// Store 5 to foo-&gt;bar</span></span><br><span class="line">        mov    DWORD PTR [esp], <span class="number">123</span></span><br><span class="line">        call    sendValue                     <span class="comment">// Call sendValue</span></span><br><span class="line">        mov    eax, DWORD PTR [ebx]          <span class="comment">// Load fresh value from foo-&gt;bar</span></span><br><span class="line">        mov    DWORD PTR [ebx+<span class="number">4</span>], eax</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>
<p>可以看到，尽管当编译器必须从内存中重新读取数据的时候，阻止编译器指令乱序的例子也有很多。我相信这些隐藏的规则构成了人们长期认为C语言中的volatile数据类型对正确编写多线程代码来说并不是必要的原因之一<sup>注9</sup>。</p>
<h3 id="横空出现的写操作"><a href="#横空出现的写操作" class="headerlink" title="横空出现的写操作"></a>横空出现的写操作</h3><p>指令乱序让无锁编程变得tricky?在C++11标准化之前，并没有技术上的规则来阻止编译器做tricky的优化. 具体来说，在没有任何写操作的情况下，编译器会很自由的引入写操作。下面是个非常简单的例子，也是受到Hans Boehm<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2338.html" target="_blank" rel="external">一些文章</a>中例子的启发。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> A, B;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span></span><br><span class="line"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (A)</span><br><span class="line">        B++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>尽管在实际中这看起来不太现实，没有任何东西能阻止编译器在检查变量A之前将变量B传递给寄存器，结果会生成下面的机器码：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span></span><br><span class="line"></span>&#123;</span><br><span class="line">    <span class="keyword">register</span> <span class="keyword">int</span> r = B;    <span class="comment">// Promote B to a register before checking A.</span></span><br><span class="line">    <span class="keyword">if</span> (A)</span><br><span class="line">        r++;</span><br><span class="line">    B = r;          <span class="comment">// Surprise! A new memory store where there previously was none.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>再强调一次，这时内存执行顺序的基本原则仍然遵守了。一个单线程程序可能对此一无所知。但在多线程环境下，尽管在变量A是0的时候，我们的函数却错误地消除了线程对变量B并发的修改，这和原始的代码情况不同<sup>注10</sup>。尽管我们已经用C/C++写多线程和无锁代码几十年了，这种晦涩但在技术上可行的情况也就是人们说C++不支持线程的一部分原因。</p>
<p>我不知道现实中是否有人成为这种横空出现的写操作的受害者。可能是因为我们倾向编写的无锁代码的类型（比较固定），以至于并没有太多的优化机会来适应这种模式。我觉得当我看到编译器产生这种代码变换时，我会去找相应的方法来避免其所带来的影响.如果这些发生在你身上，可以在评论中让我看到。</p>
<p>在任何的情况下，新的C++11 标准明确的说明了编译器会引入数据竞争的情况。细节可以在最近的C++11 手稿的1.10.22章节中找到</p>
<pre><code>Compiler transformations that introduce assignments to a potentially shared memory location that would not be modified by the abstract machine are generally precluded by this standard.
</code></pre><h3 id="为什么有编译器乱序"><a href="#为什么有编译器乱序" class="headerlink" title="为什么有编译器乱序"></a>为什么有编译器乱序</h3><p>就像我在文章开头提到的那样，编译器会像处理器一样以同样的原因-性能优化-来修改内存执行顺序。这种优化是现代CPU复杂性的直接产物。</p>
<p>当CPU最多只有几十万个晶体管的时候，我有点怀疑编译器在80年代早期就已经做了很多指令乱序的工作。我这个说法可能有点惊世骇俗。那时候并没有太多关于编译器乱序的观点。从那时起，根据摩尔定律，CPU的设计者将晶体管的数目成10000倍的增长，那些晶体管设计了许多trick,比如流水线，内存预取，ILP以及最近的多核。这些特征的结果就是，我们可以看到程序中指令的执行顺序在性能上能产生很大的差异。</p>
<p>Intel在1993年发布的首个Pentium处理器，其所谓的U和V管道，是我记得的第一个人们经常说起关于<a href="http://www.agner.org/optimize/microarchitecture.pdf" target="_blank" rel="external">管道和指令乱序</a>的处理器。最近，当我在Visual Studio上开始涉及X86汇编代码时。我对其中极少数的指令乱序情况感到非常惊讶。另一方面，我在Playstation 3平台上写SPU汇编代码时，发现编译器非常高效<sup>注11</sup>。这只是一些有趣的经历，并不能反应其他人的情况，当然也不影响我们在lock-free的代码中保证内存执行顺序的手段和方法<sup>注12</sup>。</p>
<h3 id="译者注"><a href="#译者注" class="headerlink" title="译者注"></a>译者注</h3><p>注1：lock free虽然翻译为无锁，但是它并不是“没有锁”的意思，“没有锁”在英文里一般是lockless。lock free考察的是若干个线程组成的系统，不管如何，总能保证至少有一个线程能make progress，因此保证系统，从整体上看，是make progress的。这样的系统或者算法实现就是lock free的。</p>
<p>注2：假设A、B的初始值都是0，那么对于单线程程序而言，foo执行完A的的值为1，B的值为0。保证这点的情况下，编译器可以随意优化。这里重要的是影响和效果。</p>
<p>注3：很多时候我们把barrier分为两种：compiler级别和cpu级别。compiler级别的memory barrier只阻止编译器乱序，不影响CPU乱序，不对CPU乱序执行进行约束；而CPU级别的memory barrier则束缚了编译器和cpu两者的乱序。</p>
<p>注4：在linux里，<code>barrier()</code>是编译器级别的memory barrier；<code>smp_wb()</code>是cpu级别的memory barrier。</p>
<p>很多朋友们可能一直存在一个疑问：在linux下，在单处理器(Uniprocessor)环境中，这里的cpu级别的memory barrier退化为编译器级别的memory barrier，仅仅束缚编译器的乱序能力，却不影响cpu，那么仅仅使用compiler barrier是否足够？</p>
<p>这是因为根据<a href="https://www.kernel.org/doc/Documentation/memory-barriers.txt" target="_blank" rel="external">文档</a>，</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SMP memory barriers are reduced to compiler barriers on uniprocessor compiled systems because it is assumed that a CPU will appear to be self-consistent, and will order overlapping accesses correctly with respect to itself.</span><br></pre></td></tr></table></figure>
<p>也就是说，在linux下，对单核处理器有两个前置条件：</p>
<p>1，单核不具有多核处理中存在的cache coherence问题。</p>
<p>2，在单核cpu上乱序执行指令的线程在被调度出去发生上下文切换时，会把乱序的指令流水撤销或者提交。</p>
<p>因此，单核单线程、单核多线程都不需要担心cpu乱序执行问题。</p>
<p>注5：C++11引入的feature。在C++11中，除了上面例子用到的<code>std::memory_order_release</code>之外，还有如下的内存序选项：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">memory_order_relaxed,</span><br><span class="line">memory_order_consume,</span><br><span class="line">memory_order_acquire,</span><br><span class="line">memory_order_release,</span><br><span class="line">memory_order_acq_rel,</span><br><span class="line">memory_order_seq_cst</span><br></pre></td></tr></table></figure>
<p>关于它们的语义和用法，请继续关注我们的深入探索并发编程系列，或者参考《C++ Concurrency In Action》这本书</p>
<p>注6：gcc提供了必须inline和必须不inline的feature，很有意思。</p>
<p>void <strong>attribute</strong> ((noinline)) foo()<br>{<br>  …<br>}</p>
<p>void <strong>attribute</strong> ((always_inline)) foo()<br>{<br>  …<br>}</p>
<p>注7：指在gcc中，加了pure attribute的函数：</p>
<p>void <strong>attribute</strong> ((pure)) foo()<br>{<br>  …<br>}</p>
<p>根据gcc文档，pure属性是用来修饰这样的函数：该函数除了返回一些值之外，不会产生其他作用和影响；并且它的返回值只依赖于它的输入参数和一些全局变量，比如说<code>strlen</code>和<code>memcmp</code>.</p>
<p>因此，对于这类函数，gcc就可以施展手脚，优化一番了。比如说，</p>
<p>int <strong>attribute</strong> ((pure)) strlen(char *p)<br>{<br>  …<br>}</p>
<p>那么假如你写了这样的代码：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span> *p = <span class="string">"abc"</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="built_in">strlen</span>(p); i++) &#123;</span><br><span class="line">  <span class="comment">//do sth</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那么gcc可以将它优化为：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span> *p = <span class="string">"abc"</span>;</span><br><span class="line"><span class="keyword">int</span> tmp = <span class="built_in">strlen</span>(p);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; tmp; i++) &#123;</span><br><span class="line">  <span class="comment">//do sth</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注8：Link-time Code Generation，一般简写为LTCG，主要针对不同编译单元(compilation unit)间的函数定义和调用进行优化。更多细节除了编译器官方文档外，可以参考<a href="http://arstechnica.com/civis/viewtopic.php?t=629188" target="_blank" rel="external">这里</a>和<a href="http://stackoverflow.com/questions/3546748/are-c-c-compilers-optimizing-across-compilation-units" target="_blank" rel="external">这里</a>。</p>
<p>注9：C/C++中的volatile常常被人错误使用，很多朋友错误以为它和Java中的volatile一样。其实不然。</p>
<p>在C/C++中的volatile，有两个重要特点：</p>
<p>1，它不提供任何的防止乱序的功能。</p>
<p>2，它不保证是原子的。</p>
<p>也就是说，以下操作不一定是原子的：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">volatile</span> <span class="keyword">int64_t</span> a = <span class="number">12345671234567</span>;</span><br></pre></td></tr></table></figure>
<p>不考虑具体的、特定的平台和环境，以下操作是未定义行为：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">volatile</span> <span class="keyword">int</span> is_ready = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> info = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">void</span> thread_A</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">while</span>(is_ready == <span class="number">0</span>)</span><br><span class="line">  &#123;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//use info;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">void</span> thread_B</span><br><span class="line">&#123;</span><br><span class="line">  info = <span class="number">123</span>;</span><br><span class="line">  is_ready = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当线程A发现is_ready不等于0而退出循环时，不能保证线程B已经执行了<code>info=123</code>，因为volatile不提供memory ordering保证，线程B里的两条语句可能被CPU乱序执行(顺便一说，在Intel X86体系结构下，这两条语句不会被CPU乱序执行)。</p>
<p>正确的做法建立happens-before关系。更多细节，敬请继续关注我们的深入探索并发编程系列。</p>
<p>注10：在多线程环境下，本来是要对B进行并发修改的，优化后却变成了对局部寄存器变量的修改，显然是不符合预期的。</p>
<p>注11：原文为really went to town，这里的意思是说，和前面的x86中的极少数乱序相比，在Playstation 3下可以看到大量的乱序情况。</p>
<p>注12：本文的重点是编译器的乱序；关于更多CPU乱序的细节和内容，请参考<a href="http://www.chongh.wiki/blog/2016/08/11/memoryreorder/" target="_blank" rel="external">上一篇</a>文章。</p>
<h3 id="Acknowledgement"><a href="#Acknowledgement" class="headerlink" title="Acknowledgement"></a>Acknowledgement</h3><p>本文由 <a href="http://weibo.com/2767520802/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="external">Diting0x</a> 与 <a href="http://weibo.com/yebangyu" target="_blank" rel="external">睡眼惺忪的小叶先森</a> 共同完成，在原文的基础上添加了许多精华注释，帮助大家理解。</p>
<p>感谢好友<a href="http://weibo.com/u/1707881862?topnav=1&amp;wvr=6&amp;topsug=1&amp;is_all=1" target="_blank" rel="external">小伙伴-小伙伴儿 </a>与<a href="http://weibo.com/u/2495479763?topnav=1&amp;wvr=6&amp;topsug=1&amp;is_all=1" target="_blank" rel="external">skyline09_ </a>阅读了初稿，并给出宝贵的意见。</p>
<p>原文： <a href="http://preshing.com/20120625/memory-ordering-at-compile-time/" target="_blank" rel="external">http://preshing.com/20120625/memory-ordering-at-compile-time/</a></p>
<p>本文遵守Attribution-NonCommercial-NoDerivatives 4.0 International License (CC BY-NC-ND 4.0)<br>仅为学习使用，未经博主同意，请勿转载<br>本系列文章已经获得了原作者preshing的授权。版权归原作者和本网站共同所有</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;写在最前：掌握并发编程非常困难，除了多读书、多写代码、多调试、多和朋友讨论，别无他法。&lt;br&gt;
    
    </summary>
    
      <category term="High-performance" scheme="http://yoursite.com/categories/High-performance/"/>
    
    
  </entry>
  
  <entry>
    <title>深入探索并发编程系列(五)-将内存乱序逮个正着</title>
    <link href="http://yoursite.com/blog/2016/08/11/memoryreorder/"/>
    <id>http://yoursite.com/blog/2016/08/11/memoryreorder/</id>
    <published>2016-08-11T03:03:27.000Z</published>
    <updated>2016-11-01T17:00:23.000Z</updated>
    
    <content type="html"><![CDATA[<p>当用C/C++编写无锁代码时，一定要小心谨慎，以保证正确的内存顺序。不然的话，会发生一些诡异的事情。</p>
<a id="more"></a>
<p>Intel在<a href="http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html" target="_blank" rel="external">x86/x64体系结构手册</a>的Volume 3, §8.2.3 中列出了一些可能会发生的诡异的事情。这里介绍其中一个最简单的例子。假设在内存中有两个整型变量<code>x</code>和<code>y</code>，都初始化为0。两个处理器并行执行下面的机器码：</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/memoryreorder1.png" alt=""></p>
<p>不要被上面的汇编代码给吓坏了。这个例子的确是阐述CPU执行顺序的最好方式。每个处理器将1写入其中一个整型变量中，然后将另一个整型变量读取到寄存器中。（<code>r1</code>和<code>r2</code>只是x86中真实寄存器-如eax寄存器-的代表符号).</p>
<p>现在不管哪个处理器先将1写入内存，都想当然的认为另一个处理器会读到这个值，这就意味着最后结果中要么<code>r1=1</code>，要么<code>r2=1</code>，要么这两个结果同时满足。但根据Intel手册，却不是这么回事。手册上说在这个例子里，最终<code>r1</code>和<code>r2</code>的值都有可能等于0。至少可以这么说，这个结果是不太符合大家直觉的。</p>
<p>可以这么理解：Intel x86/x64处理器，和大部分处理器家族一样，在保证不改变一个单线程程序执行的基础上，会根据一定的规则将机器指令对内存的操作顺序重新排序。具体来说，对于不同内存变量的写读操作，处理器保留乱序的权利<sup>注1</sup>。 结果就好像是指令就是按照下图这个顺序执行的：</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/memoryorder2.png" alt=""></p>
<h3 id="指令乱序重现"><a href="#指令乱序重现" class="headerlink" title="指令乱序重现"></a>指令乱序重现</h3><p>能被告知这种诡异的事情会发生总是好的，但眼见才为实。这也就是我为什么要写个小程序来说明这种重新排序会发生的原因。你可以在<a href="http://7xppf1.com1.z0.glb.clouddn.com/ordering.zip" target="_blank" rel="external">这里</a>下载源码。</p>
<p>代码样例分别包含Win32和POSIX版本。代码中会派生出两个工作线程不断重复上述的事务，主线程用来同步这些工作并检查最终结果。</p>
<p>下面是第一个工作线程的源码。<code>X</code>,<code>Y</code>,<code>r1</code>和<code>r2</code>都是全局变量，POSIX信号量用来协调每个循环的开始和结束。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">sem_t</span> beginSema1;</span><br><span class="line"><span class="keyword">sem_t</span> endSema;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> X, Y;</span><br><span class="line"><span class="keyword">int</span> r1, r2;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">thread1Func</span><span class="params">(<span class="keyword">void</span> *param)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">    <span class="function">MersenneTwister <span class="title">random</span><span class="params">(<span class="number">1</span>)</span></span>;                <span class="comment">// Initialize random number generator</span></span><br><span class="line">    <span class="keyword">for</span> (;;)                                  <span class="comment">// Loop indefinitely</span></span><br><span class="line">    &#123;</span><br><span class="line">        sem_wait(&amp;beginSema1);                <span class="comment">// Wait for signal from main thread</span></span><br><span class="line">        <span class="keyword">while</span> (random.integer() % <span class="number">8</span> != <span class="number">0</span>) &#123;&#125;  <span class="comment">// Add a short, random delay</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// ----- THE TRANSACTION! -----</span></span><br><span class="line">        X = <span class="number">1</span>;</span><br><span class="line">        <span class="function"><span class="keyword">asm</span> <span class="title">volatile</span><span class="params">(<span class="string">""</span> ::: <span class="string">"memory"</span>)</span></span>;        <span class="comment">// Prevent compiler reordering</span></span><br><span class="line">        r1 = Y;</span><br><span class="line"></span><br><span class="line">        sem_post(&amp;endSema);                   <span class="comment">// Notify transaction complete</span></span><br><span class="line">    &#125;</span><br><span class="line">    return <span class="literal">NULL</span>;  <span class="comment">// Never returns</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>每个事务前用一个短暂、随机的延迟用来错开线程的时间。记住，这里有两个工作线程，我们要试着将他们的指令重叠。随机延迟是用我前面文章，<a href="http://www.chongh.wiki/blog/2016/06/20/mutexperf/" target="_blank" rel="external">锁不慢；锁竞争慢
</a>和<a href="http://www.chongh.wiki/blog/2016/07/11/recursivemutex/" target="_blank" rel="external">实现递归锁</a>的使用过的<code>MersenneTwister</code>来实现的。</p>
<p>别被上面代码中的<code>asm volatile</code>给吓坏了。其作用就是直接告诉<a href="https://en.wikipedia.org/wiki/Memory_ordering#Compiler_memory_barrier" target="_blank" rel="external">GCC编译器在生成机器码的时候不要重新安排store和load操作</a>，以防在优化期间做了手脚<sup>注2</sup>. 我们可以检查下面的汇编代码来验证这个过程。意料之中，store和load操作按照我们想要的顺序执行。之后的指令将<code>eax</code>寄存器中的结果写回到全局变量<code>r1</code>中。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ gcc -O2 -c -S -masm=intel ordering.cpp</span><br><span class="line">$ cat ordering.s</span><br><span class="line">    ...</span><br><span class="line">    mov    DWORD PTR _X, <span class="number">1</span></span><br><span class="line">    mov    eax, DWORD PTR _Y</span><br><span class="line">    mov    DWORD PTR _r1, eax</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<p>主线程的源码如下。其执行所有的管理工作。初始化后，进入无限循环，在每次迭代开始工作线程之前会重新设置X和Y为0。</p>
<p>注意<code>sem_post</code>之前所有有可能发生的共享内存写操作，以及<code>sem_wait</code>之后所有有可能发生的共享内存读操作。工作线程在和主线程通信的过程中也要遵守同样的规则。信号量为每个平台提供了acquire和release语义。这意味着我们可以保证初始值<code>X=0</code>和<code>Y=0</code>可以完全传播到工作线程中，<code>r1</code>和<code>r2</code>的结果也会被完整传回来。换句话说，信号量阻止了乱序<sup>注3</sup>，可以让我们全心关注实验本身。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span><br><span class="line"></span>&#123;</span><br><span class="line">    <span class="comment">// Initialize the semaphores</span></span><br><span class="line">    sem_init(&amp;beginSema1, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">    sem_init(&amp;beginSema2, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">    sem_init(&amp;endSema, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Spawn the threads</span></span><br><span class="line">    <span class="keyword">pthread_t</span> thread1, thread2;</span><br><span class="line">    pthread_create(&amp;thread1, <span class="literal">NULL</span>, thread1Func, <span class="literal">NULL</span>);</span><br><span class="line">    pthread_create(&amp;thread2, <span class="literal">NULL</span>, thread2Func, <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Repeat the experiment ad infinitum</span></span><br><span class="line">    <span class="keyword">int</span> detected = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> iterations = <span class="number">1</span>; ; iterations++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// Reset X and Y</span></span><br><span class="line">        X = <span class="number">0</span>;</span><br><span class="line">        Y = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">// Signal both threads</span></span><br><span class="line">        sem_post(&amp;beginSema1);</span><br><span class="line">        sem_post(&amp;beginSema2);</span><br><span class="line">        <span class="comment">// Wait for both threads</span></span><br><span class="line">        sem_wait(&amp;endSema);</span><br><span class="line">        sem_wait(&amp;endSema);</span><br><span class="line">        <span class="comment">// Check if there was a simultaneous reorder</span></span><br><span class="line">        <span class="keyword">if</span> (r1 == <span class="number">0</span> &amp;&amp; r2 == <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            detected++;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%d reorders detected after %d iterations\n"</span>, detected, iterations);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return <span class="number">0</span>;  <span class="comment">// Never returns</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后，关键时刻到了。这是在Intel Xeon W3520中运行<a href="http://www.cygwin.com/" target="_blank" rel="external">Cygin</a>的输出。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/memoryorder3.png" alt=""></p>
<p>在运行期间，每6600次迭代差不多能检测到一次乱序。当我在Core 2 Duo E6300处理器Ubuntu系统中测试时，乱序的次数更少见。大家开始对这种微妙的timing bug是如何能蔓延到无锁代码中而不被检测到感到刺激。</p>
<p>现在，假设你想避免这种乱序，至少有两种方法可以做到。其中一种方法就是设置线程亲和力（thread affinities），以让两个工作线程能在同一个CPU核上独立运行。Pthreads中没有可移植的方法设置亲和力，但在Linux上，可以这样来实现：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cpu_set_t</span> cpus;</span><br><span class="line">CPU_ZERO(&amp;cpus);</span><br><span class="line">CPU_SET(<span class="number">0</span>, &amp;cpus);</span><br><span class="line">pthread_setaffinity_np(thread1, <span class="keyword">sizeof</span>(<span class="keyword">cpu_set_t</span>), &amp;cpus);</span><br><span class="line">pthread_setaffinity_np(thread2, <span class="keyword">sizeof</span>(<span class="keyword">cpu_set_t</span>), &amp;cpus);</span><br></pre></td></tr></table></figure>
<p>这样修改之后，乱序就不会发生了。那是因为尽管当线程在任一时间抢占处理器并被重新调度，单个处理器绝不会让自己的操作乱序<sup>注4</sup>。当然了，将两个线程都锁到一个单独的核中，其它核就用不上了。</p>
<p>与此相关的是，我在Playstation 3上编译并运行了这份代码，没有检测到乱序的情况。这意味着（不能确信)在PPU里的两个硬件线程可能会充当一个单处理器，具有细粒度的硬件调度能力。</p>
<h3 id="用Storeload-Barrier来避免"><a href="#用Storeload-Barrier来避免" class="headerlink" title="用Storeload Barrier来避免"></a>用Storeload Barrier来避免</h3><p>在这个例子中，另一种阻止内存乱序的方法是在两条指令间引入一个CPU级的Memory Barrier。在这里，我们要避免store操作紧接load操作的乱序情况。用惯用的barrier行话来说， 我们需要的是一个Storeload barrier。</p>
<p>在x86/x64处理器中，没有特定的指令用来充当Storeload barrier,但有其它的一些指令能做到甚至更多的事情。<code>mfence</code>指令就是一个full memory barrier，可以避免任何形式的内存乱序。在GCC中，实现方式如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (;;)                                  <span class="comment">// Loop indefinitely</span></span><br><span class="line">&#123;</span><br><span class="line">    sem_wait(&amp;beginSema1);                <span class="comment">// Wait for signal from main thread</span></span><br><span class="line">    <span class="keyword">while</span> (random.integer() % <span class="number">8</span> != <span class="number">0</span>) &#123;&#125;  <span class="comment">// Add a short, random delay</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// ----- THE TRANSACTION! -----</span></span><br><span class="line">    X = <span class="number">1</span>;</span><br><span class="line">    <span class="function"><span class="keyword">asm</span> <span class="title">volatile</span><span class="params">(<span class="string">"mfence"</span> ::: <span class="string">"memory"</span>)</span></span>;  <span class="comment">// Prevent memory reordering</span></span><br><span class="line">    r1 = Y;</span><br><span class="line"></span><br><span class="line">    sem_post(&amp;endSema);                   <span class="comment">// Notify transaction complete</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同样地，可以检查下面的汇编代码来验证。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">   mov    DWORD PTR _X, <span class="number">1</span></span><br><span class="line">   mfence</span><br><span class="line">   mov    eax, DWORD PTR _Y</span><br><span class="line">   mov    DWORD PTR _r1, eax</span><br><span class="line">   ...</span><br></pre></td></tr></table></figure>
<p>这样修改之后，内存乱序就不会发生了，并且我们依然允许两个线程分别运行在不同的CPU核中<sup>注5</sup>。</p>
<h3 id="类似指令与不同平台"><a href="#类似指令与不同平台" class="headerlink" title="类似指令与不同平台"></a>类似指令与不同平台</h3><p>有趣的是，<code>mfence</code>并不是x86/x64平台中能唯一充当full memory barrier的指令。在这些处理器中，假设你不使用SSE指令或者写结合内存(Write-combined Memory)（例子中也并没有用到），任何带lock的指令，比如<code>xchg</code>，也能作为一个full memory barrier。实际上，Microsoft C++编译器在你使用<code>MemoryBarrier</code>时会生成<code>xchg</code>指令，至少Visualstudio 2008是这么做的</p>
<p><code>mfence</code>指令是x86/x64平台独有的<sup>注6</sup>。如果你想让代码具有可移植性，可以将这种固有特性写成一个预处理的宏。Linux内核将其封装成一个叫做<code>smp_mb</code>的宏，以及相关的宏<code>smp_rmb</code>和<code>smp_wmb</code>宏<sup>注7</sup>，并提供了<a href="http://lxr.free-electrons.com/ident?i=smp_mb" target="_blank" rel="external">在不同架构中的不同实现方法</a>。 例如，在PowerPC中，<code>smp_mb</code>宏是通过<code>sync</code>来实现的.</p>
<p>在这些不同的CPU家族中，每种CPU都有各自的指令来保证内存访问顺序，每个编译器通过不同的内置属性展现出来，每种跨平台的项目都会实现自己的可移植层。 然而，这些都不能让无锁编程变得更加简单。 这就是<a href="http://www.open-std.org/JTC1/sc22/wg21/docs/papers/2007/n2427.html" target="_blank" rel="external">C++11原子库标准</a>在最近被提出来的部分原因。这是标准化的一次尝试，可能会让写可移植性的无锁代码变得更加简单。</p>
<h3 id="译者注"><a href="#译者注" class="headerlink" title="译者注"></a>译者注</h3><p>注1：注意，这里说的是写读乱序，而且是对不同变量的写读操作的乱序。在Intel x86/x64处理器中，读读、写写、读写、以及写读同一个内存变量，CPU是不会乱序的。</p>
<p>注2：<code>asm volatile(&quot;&quot; ::: &quot;memory&quot;)</code>是一条编译器级别的Memory Barrier，可以防止编译器对相邻指令进行乱序，但是它对CPU乱序是没有影响的；也就是说它仅仅束缚了编译器的乱序优化，不会阻止CPU可能的乱序执行。这么做自然是将编译器的干扰和影响降到最低，好让我们专注观察CPU的执行行为。</p>
<p>注3：请务必注意，这里说的阻止乱序是指防止了向<code>sem_wait</code>和<code>sem_post</code>之外的乱序，不阻止它们之间的乱序。举个例子：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mutex.lock();</span><br><span class="line">a=<span class="number">1</span>;</span><br><span class="line">b=<span class="number">2</span>;</span><br><span class="line">mutex.unlock;</span><br></pre></td></tr></table></figure>
<p>这里lock保证了<code>a=1</code>和<code>b=2</code>这两行代码不会被拉到lock之上执行；同理，也不会被拉到unlock之下执行。</p>
<p>因此，我们说lock和unlock分别提供了acquire语义和release语义。但是lock和unlock之间的代码是允许乱序的，也可能发生乱序的，而这正是这个实验的目的。</p>
<p>这里，lock对应文中的<code>sem_wait</code>，unlock对应<code>sem_post</code>。借此机会，读者可以对锁有更好的认识。</p>
<p>注4：也就是说，单核多线程、多核单线程程序不用担心memory reordering问题，只有多核多线程才需要小心谨慎。为什么呢？请看下面的注5。</p>
<p>注5：到目前为止，读者可能会对通篇文章里的内容有两个疑问：</p>
<p>1，为什么CPU要乱序执行，难道是考虑性能吗？那为什么乱序就能提升性能？</p>
<p>2，为什么在Intel X86/64架构下，就只有写读（Store Load）发生乱序呢？读读呢？读写呢？</p>
<p>要明白这两个问题，我们首先得知道cache coherency，也就是所谓的cache一致性。</p>
<p>在现代计算机里，一般包含至少三种角色：cpu、cache、内存。一般说来，内存只有一个；CPU Core有多个；cache有多级，cache的基本块单位是cacheline，大小一般是64B-256B。</p>
<p>每个cpu core有自己的私有的cache(有一级cache是共享的)，而cache只是内存的副本。那么这就带来一个问题：如何保证每个cpu core中的cache是一致的？</p>
<p>在广泛使用的cache一致性协议即MESI协议中，cacheline有四种状态：Modified、Exclusive、Shared、Invalid，分别表示修改、独占、共享、无效。</p>
<p>当某个cpu core写一个内存变量时，往往是（先）只修改cache，那么这就会导致不一致。为了保证一致，需要先把其他core的对应的cacheline都invalid掉，给其他core们发送invalid消息，然后等待它们的response。</p>
<p>这个过程是耗时的，需要执行写变量的core等待，阻塞了它后面的操作。为了解决这个问题，cpu core往往有自己专属的store buffer。</p>
<p>等待其他core给它response的时候，就可以先写store buffer，然后继续后面的读操作，对外表现就是写读乱序。</p>
<p>因为写操作是写到store buffer中的，而store buffer是私有的，对其他core是透明的，core1无法访问core2的store buffer。因此其他core读不到这样的修改。</p>
<p>这就是大概的原理。MESI协议非常复杂，背后的技术也很有意思。</p>
<p>注6：不建议使用这么原生(raw) 的memory barrier。在GCC下，推荐使用<code>__sync_synchronize</code>。</p>
<p>注7：X86下，<code>smp_wmb</code>是一个空宏，什么也不做；而<code>smp_rmb</code>则不是。想想看，为什么。</p>
<p>注8：作为练习，请读者朋友们分析以下问题，其中A、B、C的初值都是0</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">thread1(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">  A = <span class="number">1</span>;</span><br><span class="line">  cpu_barrier();</span><br><span class="line">  B = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line">thread2(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">while</span> (B != <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">continue</span>;</span><br><span class="line">  compiler_barrier();</span><br><span class="line">  C = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line">thread3(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">while</span> (C != <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">continue</span>;</span><br><span class="line">  compiler_barrier();</span><br><span class="line">  assert(A != <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中，<code>cpu_barrier</code>是cpu级别的memory barrier，影响cpu和编译器，防止它们乱序；<code>compiler_barrier</code>只防止编译器乱序。</p>
<p>问题：thread3中的断言是否可能会失败？为什么？别急着回答，考虑平台是否是x86？考虑单核多线程、多核单线程、多核多线程？</p>
<p>另外，这篇流传很广的文章有错，务必小心：<a href="http://blog.csdn.net/jnu_simba/article/details/22985913" target="_blank" rel="external">http://blog.csdn.net/jnu_simba/article/details/22985913</a></p>
<p>注9：注意，我们的讨论只针对普通指令，对于SSE等特殊指令，情况可能完全不同。这点读者务必注意。</p>
<h3 id="Acknowledgement"><a href="#Acknowledgement" class="headerlink" title="Acknowledgement"></a>Acknowledgement</h3><p>本文由 <a href="http://weibo.com/2767520802/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="external">Diting0x</a> 与 <a href="http://weibo.com/yebangyu" target="_blank" rel="external">睡眼惺忪的小叶先森</a> 共同完成，在原文的基础上添加了许多精华注释，帮助大家理解。</p>
<p>感谢好友<a href="http://weibo.com/u/1707881862?topnav=1&amp;wvr=6&amp;topsug=1&amp;is_all=1" target="_blank" rel="external">小伙伴-小伙伴儿 </a>与<a href="http://weibo.com/u/2495479763?topnav=1&amp;wvr=6&amp;topsug=1&amp;is_all=1" target="_blank" rel="external">skyline09_ </a>阅读了初稿，并给出宝贵的意见。</p>
<p>原文： <a href="http://preshing.com/20120515/memory-reordering-caught-in-the-act/" target="_blank" rel="external">http://preshing.com/20120515/memory-reordering-caught-in-the-act/</a></p>
<p>本文遵守Attribution-NonCommercial-NoDerivatives 4.0 International License (CC BY-NC-ND 4.0)<br>仅为学习使用，未经博主同意，请勿转载<br>本系列文章已经获得了原作者preshing的授权。版权归原作者和本网站共同所有</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;当用C/C++编写无锁代码时，一定要小心谨慎，以保证正确的内存顺序。不然的话，会发生一些诡异的事情。&lt;/p&gt;
    
    </summary>
    
      <category term="High-performance" scheme="http://yoursite.com/categories/High-performance/"/>
    
    
  </entry>
  
  <entry>
    <title>深入探索并发编程系列(四)-实现递归锁</title>
    <link href="http://yoursite.com/blog/2016/07/11/recursivemutex/"/>
    <id>http://yoursite.com/blog/2016/07/11/recursivemutex/</id>
    <published>2016-07-11T00:47:43.000Z</published>
    <updated>2016-11-01T17:00:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>当你要为多CPU核优化代码时，有时需要去实现一种新的同步原语。<br>虽然我不鼓励这么做，但这样的情况却时常发生。就在你打算开始这么做的时候，可能会先找一些例子来参考。这种过程无疑是搬起石头砸自己的脚，但却能减少你再次犯这种错误的次数，这样起码还能给你留下几个脚趾头继续走路。</p>
<a id="more"></a>
<p>在<a href="http://www.chongh.wiki/blog/2016/07/04/writelightweightmutex/" target="_blank" rel="external">上一篇</a>文章中，教大家在Win32平台下用C++实现了Benaphore同步原语。Benaphore不是无锁(lock-free)的（自己本身就是锁)<sup>注1</sup>,但Benaphore的实现可以作为在用户空间实现同步原语的案例，非常简单而又具有指导性意义。当不存在锁竞争时，它也的确能带来非常低的开销。</p>
<p>实现中的不足就是它不是可递归(non recursive)的。这意味着如果同一个线程试图两次获取同一把锁，就会发生死锁<sup>注2</sup>。本文将其实现扩展以支持可递归锁。</p>
<p>当你有个模块想通过自身提供的公共接口调用自己的时候，可递归锁就显得很有用处了。举个例子，在内存管理中，你可能会遇到这样的代码：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span>* MemoryManager::Realloc(<span class="keyword">void</span>* ptr, <span class="keyword">size_t</span> size)</span><br><span class="line">&#123;</span><br><span class="line">    AUTO_LOCK_MACRO(m_lock);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (ptr == <span class="literal">NULL</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        return Alloc(size);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (size == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        Free(size);</span><br><span class="line">        return <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span>* MemoryManager::Alloc(<span class="keyword">size_t</span> size)</span><br><span class="line">&#123;</span><br><span class="line">    AUTO_LOCK_MACRO(m_lock);</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>显然，<code>AUTO_LOCK_MACRO</code>也是C++中的一个宏，用来获取锁并在我们想退出函数域的时候自动释放锁<sup>注3</sup>。</p>
<p>可以看出，如果把<code>NULL</code>传给<code>Realloc</code>,<code>Realloc</code>函数会第一次获取锁，当调用到<code>Alloc</code>函数的时候，会第二次(递归)获取锁。显然，在这个特殊的例子中，要避免锁的递归使用，修改起来很容易，但在一些大型多线程的项目中，你很有可能还会遇到其它的例子。</p>
<p>可以按照以下方法来将Benaphore的实现扩展以支持可递归锁。我在Benaphore类中增加了两个新成员：<code>m_owner</code>，用来保存当前拥有者的线程ID(TID)，以及<code>m_recursion</code>，用来保存递归计数器。</p>
<p>有心的读者可能会注意到这份代码中没有采用新的<a href="http://www.open-std.org/JTC1/sc22/wg21/docs/papers/2007/n2427.html" target="_blank" rel="external">C++ 11原子库标准</a>。这么做是为了从长远来看让这份代码仍然兼容。然而，在2000年代中期的游戏业中，我们就采用了这种方式。下面的代码可以用任意的Microsoft编译器编译，并且所有与Windows相关的调用在其它平台下都有相对应的调用方式。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Define this to &#123;&#125; in a retail build:</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> LIGHT_ASSERT(x) &#123; <span class="meta-keyword">if</span> (!(x)) DebugBreak(); &#125;</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> RecursiveBenaphore</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    LONG m_counter;</span><br><span class="line">    DWORD m_owner;</span><br><span class="line">    DWORD m_recursion;</span><br><span class="line">    HANDLE m_semaphore;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    RecursiveBenaphore::RecursiveBenaphore()</span><br><span class="line">    &#123;</span><br><span class="line">        m_counter = <span class="number">0</span>;</span><br><span class="line">        m_owner = <span class="number">0</span>;            <span class="comment">// an invalid thread ID</span></span><br><span class="line">        m_recursion = <span class="number">0</span>;</span><br><span class="line">        m_semaphore = CreateSemaphore(NULL, <span class="number">0</span>, <span class="number">1</span>, NULL);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    RecursiveBenaphore::~RecursiveBenaphore()</span><br><span class="line">    &#123;</span><br><span class="line">        CloseHandle(m_semaphore);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">Lock</span><span class="params">()</span></span><br><span class="line">    </span>&#123;</span><br><span class="line">        DWORD tid = GetCurrentThreadId();</span><br><span class="line">        <span class="keyword">if</span> (_InterlockedIncrement(&amp;m_counter) &gt; <span class="number">1</span>) <span class="comment">// x86/64 guarantees acquire semantics</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (tid != m_owner)</span><br><span class="line">                WaitForSingleObject(m_semaphore, INFINITE);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//--- We are now inside the Lock ---</span></span><br><span class="line">        m_owner = tid;</span><br><span class="line">        m_recursion++;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">Unlock</span><span class="params">()</span></span><br><span class="line">    </span>&#123;</span><br><span class="line">        DWORD tid = GetCurrentThreadId();</span><br><span class="line">        LIGHT_ASSERT(tid == m_owner);</span><br><span class="line">        DWORD recur = --m_recursion;</span><br><span class="line">        <span class="keyword">if</span> (recur == <span class="number">0</span>)</span><br><span class="line">            m_owner = <span class="number">0</span>;</span><br><span class="line">        DWORD result = _InterlockedDecrement(&amp;m_counter); <span class="comment">// x86/64 guarantees release semantics</span></span><br><span class="line">        <span class="keyword">if</span> (result &gt; <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (recur == <span class="number">0</span>)</span><br><span class="line">                ReleaseSemaphore(m_semaphore, <span class="number">1</span>, <span class="literal">NULL</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//--- We are now outside the Lock ---</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>在<a href="http://preshing.com/20120226/roll-your-own-lightweight-mutex/" target="_blank" rel="external">原始Benaphore</a>类中,第一个调用<code>Lock</code>的线程会获取拥有权而不必跳转到开销昂贵的内核调用中。同时也会做一些记录：将<code>m_owner</code>设为自己的TID，<code>m_recursion</code>设为1。如果同一个线程再次调用<code>Lock</code>，<code>m_counter</code>和<code>m_recursion</code>的值都会加1.</p>
<p>类似的，当同一个线程调用<code>Unlock</code>时，会将<code>m_counter</code>和<code>m_recursion</code>的值减1。但当<code>m_recursion</code>的值被减到0时，只会调用<code>ReleaseSemaphore</code>一次。如果此时<code>m_recursion</code>的值仍大于0，意味着当前线程在外部作用域内仍然持有这把锁，这时候将拥有权交给其它线程是不安全的。</p>
<p>这时，你在网上随便一搜，就能找到许多有问题的无锁代码和同步原语。那你凭什么会相信本文中的代码有什么不一样呢？<br>首先，本文的代码经过了压力测试(stress tested）。在我看来，这是最有价值的东西。我写了个小的测试程序，其生成许许多多的线程，每个线程都获取锁N(随机)次，递归深度也是随机的。它会更新每把锁里面共享的数据并做一致性检查。可以在<a href="http://7xppf1.com1.z0.glb.clouddn.com/RecursiveBenaphoreTest.zip" target="_blank" rel="external">这里</a>下载源码</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/recursivemutex.png" alt="recursivemutex"></p>
<p>为了更好的测试，以下是<code>TryLock</code>方法</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">TryLock</span><span class="params">()</span></span><br><span class="line"></span>&#123;</span><br><span class="line">    DWORD tid = GetCurrentThreadId();</span><br><span class="line">    <span class="keyword">if</span> (m_owner == tid)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// Already inside the lock</span></span><br><span class="line">        _InterlockedIncrement(&amp;m_counter);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        LONG result = _InterlockedCompareExchange(&amp;m_counter, <span class="number">1</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">if</span> (result != <span class="number">0</span>)</span><br><span class="line">            return <span class="literal">false</span>;</span><br><span class="line">        <span class="comment">//--- We are now inside the Lock ---</span></span><br><span class="line">        m_owner = tid;</span><br><span class="line">    &#125;</span><br><span class="line">    m_recursion++;</span><br><span class="line">    return <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对细节感兴趣的人，可以继续往下看：</p>
<ul>
<li><p>在<code>RecursiveBenaphore::Unlock</code>方法中，在调用<code>_InterlockedDecrement</code>之前将<code>m_owner</code>设回0是非常重要的，否则，有可能会发生数据破坏。举个例子，假设两个线程的TID分别为123与456。线程123刚完成了对<code>Unlock</code>的调用并将<code>m_owner</code>设为123。接下来有可能会发生下面的事情：</p>
<ol>
<li>两个线程同时进入<code>RecursiveBenaphore::Unlock</code></li>
<li>线程456执行<code>_InterlockedIncrement</code>，得到返回值1，因此会跳过<code>WaitForSingleObject</code></li>
<li>线程123执行<code>_InterlockedIncrement</code>，得到返回值2</li>
<li>由于线程456还没来得及更新<code>m_owner</code>的值，线程123执行检查发现<code>id == m_owner</code>，也会跳过<code>WaitForSingleObject</code></li>
</ol>
<p>不久之后，两个线程都从<code>Lock</code>中返回，每个线程都认为自己获取了锁。这时锁中保护的数据就有可能被破坏。实际上，如果你下载了测试源码，并将<code>RecursiveBenaphore::Unlock</code>这一部分删除，很快就会运行失败。</p>
</li>
<li><p>另外，在<code>RecursiveBenaphore::Unlock</code>方法中，<code>m_recurtion</code>的值只有一次被拷贝到本地变量中，并从那时开始使用变量的值。在执行<code>_InterlockedDecrement</code>之后，不会再次去读取<code>m_recurtion</code>的值。那时，另一个线程可能已经改变它的值了。</p>
</li>
<li><p>你可能会注意到，<code>m_recurtion</code>的值被修改的时候，不会用到任何原子操作。那是因为在调用<code>Lock</code>中的<code>_InterlockedIncrement</code>和<code>Unlock</code>中的<code>_InterlockedDecrement</code>之间，获取锁的线程对<code>m_owner</code>和<code>m_recurtion</code>都独自占有访问权，拥有所有必要的aquire和release语义<sup>注4</sup>。在<code>m_recurtion</code>使用原子操作是没必要的，而且会很浪费。</p>
</li>
</ul>
<p>最后一点又是如何保证的呢？在非竞争情况下是通过原子操作来保证的(fast path)，而在有竞争的情况下，是通过信号量来保证的(slow path)。在X86和X64平台下，对<code>_InterlockedIncrement</code><sup>注5</sup>的调用会生成<code>lock xadd</code>指令，其充当一个完整的memory barrier<sup>注6</sup>，以确保acquire和release语义。这是x86/x64独有的性质。如果你把这份代码放到多核的iOS设备上运行，比如说IPAD2，用<code>OSAtomicIncrement32</code>替代<code>_InterlockedIncrement</code>是远远不够的。你还必须要调用<code>OSAtomicIncrement32Barrier</code>才能得到类似的保证。就算在Xbox360上，能共享Win32的API，但是却是运行在PowerPC上，正确的函数调用实际上是<code>InterlockedIncrementAcquire</code></p>
<p>读到这一章节，相信很多读者都已经懵逼了。希望这种懵逼是值得的。我会在<a href="">以后的文章</a>中更多的谈谈内存访问语义。</p>
<p>对于那些还没有钻研过同步原语的读者来说，<code>RecursiveBenaphore</code>类给大家展示了，可递归锁实现的代码是多么的微妙。 这里每个细节的存在都是有原因的，里面的执行顺序很关键，隐含的一些假设和保证都发挥着重要作用<sup>注7</sup>。</p>
<h2 id="译者注"><a href="#译者注" class="headerlink" title="译者注"></a>译者注</h2><p>注1：lock free并不是说不含锁的意思。不包含锁的英文一般是lockless。实际上，lock free考察的是由一组线程构成的一个系统。不管如何，至少能保证一个线程make progress因此保证系统是在make progress，那么这个算法或者系统或者说实现是lock free的。</p>
<p>我们知道，基于mutex的实现里，如果持有锁的线程被调度出去，那么其他线程都得等待该线程被重新调度并且等待它释放锁；假如它crash了，那么系统将无法make progress。lock free是non blocking的，一个线程被阻塞或者crash，不会影响到其他线程的正常推进。</p>
<p>注2：non recursive，不可递归的；non reentrant，不可重入的。说一把锁是non reentrant和non recursive是一个意思。</p>
<p>注3：一般说来，在工业级C++项目里不会出现这样的代码：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span></span><br><span class="line"></span>&#123;</span><br><span class="line">  mutex.lock();</span><br><span class="line">  <span class="comment">//do sth here</span></span><br><span class="line">  mutex.unlock();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>一般都是通过C++的RAII机制，利用对象的构造函数和析构函数，来封装获取锁和释放锁。例如</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> MutexGuard</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  MutexGuard(Mutex &amp;mutex):mutex_(mutex)</span><br><span class="line">  &#123;</span><br><span class="line">    mutex_.lock();</span><br><span class="line">  &#125;</span><br><span class="line">  ~MutexGuard()</span><br><span class="line">  &#123;</span><br><span class="line">    mutex_.unlock();</span><br><span class="line">  &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  Mutex &amp;mutex_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span></span><br><span class="line"></span>&#123;</span><br><span class="line">  <span class="function">MutexGuard <span class="title">guard</span><span class="params">(my_mutex)</span></span>;<span class="comment">//构造函数里调用了lock</span></span><br><span class="line">  <span class="comment">//do sth here...</span></span><br><span class="line">  <span class="comment">//......</span></span><br><span class="line">  <span class="comment">//guard 被析构，调用了unlock.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注4：后面会有文章专门介绍acquire 和release语义，这里做简单的描述。以临界区保护为例：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mutex.lock();</span><br><span class="line"><span class="comment">//critical section</span></span><br><span class="line">a = <span class="number">1</span>;</span><br><span class="line">mutex.unlock;</span><br></pre></td></tr></table></figure>
<p>我们知道，cpu和编译器是可以对代码和指令进行乱序的。然而，这里a=1这行代码不允许被拉到lock操作之前执行，也不能被拉到unlock之后执行。否则，临界区的内容就可能被多个线程读写，造成数据败坏，也无所谓临界区了。我们说lock带有acquire语义，粗俗的说就是它提供了这样的保证：它之下的代码不能被拉到它之上执行；unlock带有release语义，粗俗的说就是它提供了这样的保证：它之上的代码不能被拉到它之下执行。显然，这得程序员和编译器、CPU达成协议和共识。</p>
<p>注5：gcc下可以使用<code>__sync_add_and_fetch</code>等内置的原子操作。</p>
<p>注6：memory barrier是用来提供和保证acquire 和release语义的基础设施，用来防止CPU和编译器乱序用的。后面也会有详细介绍。</p>
<p>注7：本文讨论的都是windows下的实现，我们一起来看看linux下的情形。</p>
<p><code>pthread_mutex_t</code>默认是不可递归的，如果想让它可递归，有两种方法。</p>
<p>第一种方法非常简单，就是初始化的时候设置相应的属性即可。例如：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pthread_mutex_t</span> mutex;</span><br><span class="line"><span class="keyword">pthread_mutexattr_t</span> attr;</span><br><span class="line">pthread_mutexattr_init(&amp;attr);</span><br><span class="line">pthread_mutexattr_settype(&amp;attr, PTHREAD_MUTEX_RECURSIVE);<span class="comment">//设置可递归</span></span><br><span class="line">pthread_mutex_init(&amp;mutex, &amp;attr);</span><br></pre></td></tr></table></figure>
<p>第二种方法，就是利用mutex，我们也做一层封装。下面的代码仅供参考，仅适用于X86平台：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdint.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pthread.h&gt;</span></span></span><br><span class="line">Class MyRecursiveLock</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  MyRecursiveLock()</span><br><span class="line">  &#123;</span><br><span class="line">    lock_holder_ = <span class="literal">NULL</span>;</span><br><span class="line">    hold_counter_ = <span class="number">0</span>;</span><br><span class="line">    pthread_mutex_init(&amp;lock_, <span class="literal">NULL</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">int</span> <span class="title">lock</span><span class="params">()</span></span><br><span class="line">  </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> ret = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">pthread_t</span> curr_id = pthread_self();</span><br><span class="line">    <span class="keyword">if</span> (lock_holder_ == curr_id) &#123;</span><br><span class="line">      ++hold_counter_;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      pthread_mutex_lock(&amp;lock_);</span><br><span class="line">      lock_holder_ = curr_id;</span><br><span class="line">      hold_counter_ = <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    return ret;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">int</span> <span class="title">unlock</span><span class="params">()</span></span><br><span class="line">  </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> ret = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">pthread_t</span> curr_id = pthread_self();</span><br><span class="line">    <span class="keyword">if</span> (lock_holder_ != curr_id) &#123;</span><br><span class="line">      ret = <span class="number">-1</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (--hold_counter_ == <span class="number">0</span>) &#123;</span><br><span class="line">        lock_holder_ = <span class="literal">NULL</span>;</span><br><span class="line">        pthread_mutex_unlock(&amp;lock_);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return ret;</span><br><span class="line">  &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="keyword">pthread_mutex_t</span> lock_;</span><br><span class="line">  <span class="keyword">pthread_t</span> lock_holder_;</span><br><span class="line">  <span class="keyword">int64_t</span> hold_counter_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="Acknowledgement"><a href="#Acknowledgement" class="headerlink" title="Acknowledgement"></a>Acknowledgement</h3><p>本文由<a href="http://weibo.com/yebangyu" target="_blank" rel="external">睡眼惺忪的小叶先森</a>与<a href="http://weibo.com/2767520802/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="external">Diting0x</a> 共同完成，在原文的基础上添加了许多精华注释，帮助大家理解。</p>
<p>感谢好友<a href="http://weibo.com/u/1707881862?topnav=1&amp;wvr=6&amp;topsug=1&amp;is_all=1" target="_blank" rel="external">小伙伴-小伙伴儿 </a>与<a href="http://weibo.com/u/2495479763?topnav=1&amp;wvr=6&amp;topsug=1&amp;is_all=1" target="_blank" rel="external">skyline09_ </a>阅读了初稿，并给出宝贵的意见。</p>
<p>原文： <a href="http://preshing.com/20120305/implementing-a-recursive-mutex/" target="_blank" rel="external">http://preshing.com/20120305/implementing-a-recursive-mutex/</a></p>
<p>本文遵守Attribution-NonCommercial-NoDerivatives 4.0 International License (CC BY-NC-ND 4.0)<br>仅为学习使用，未经博主同意，请勿转载<br>本系列文章已经获得了原作者preshing的授权。版权归原作者和本网站共同所有</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;当你要为多CPU核优化代码时，有时需要去实现一种新的同步原语。&lt;br&gt;虽然我不鼓励这么做，但这样的情况却时常发生。就在你打算开始这么做的时候，可能会先找一些例子来参考。这种过程无疑是搬起石头砸自己的脚，但却能减少你再次犯这种错误的次数，这样起码还能给你留下几个脚趾头继续走路。&lt;/p&gt;
    
    </summary>
    
      <category term="High-performance" scheme="http://yoursite.com/categories/High-performance/"/>
    
    
  </entry>
  
  <entry>
    <title>深入探索并发编程系列(三)-自己动手实现轻量级锁</title>
    <link href="http://yoursite.com/blog/2016/07/04/writelightweightmutex/"/>
    <id>http://yoursite.com/blog/2016/07/04/writelightweightmutex/</id>
    <published>2016-07-04T01:16:31.000Z</published>
    <updated>2016-11-01T17:01:02.000Z</updated>
    
    <content type="html"><![CDATA[<p>在<a href="http://www.chongh.wiki/blog/2016/06/27/lightweightmutex/" target="_blank" rel="external">上一篇</a>文章中，我强调了使用轻量级锁的重要性。还提到如果你能容忍某些弊端的话，自己动手实现轻量级锁也是可以的。</p>
<a id="more"></a>
<p>为什么要这么做呢？ 在过去，一些平台(如BeOS)的本地API中并没有提供轻量级锁的实现。如今，这已经不再是要担心的问题了。那我还要重点提这些主要是觉得深入了解同步原语的实现很有意思。作为一个好奇心比较重的人，我就这么做了，实现的轻量级锁在非竞争条件下相比Windows Critical Section能减少50%的开销。[更新：更进一步研究表明，在高竞争条件下，Windows Critical Section的表现还是要好很多]。</p>
<p>准确地说，有许多方法可以完全在用户空间下实现互斥量(锁)，每种方法也都有自己的tradeoffs：</p>
<ul>
<li>Spin锁. 采用一种忙则等待的策略。可能会浪费CPU时间，最坏的情况是当多个线程运行在同一个CPU核时会导致活锁<sup>注1</sup>。尽管如此，一些程序员也已经在一些特定场景下找到了当切换到spin锁如何加速的方法。<sup>注2</sup></li>
<li>Peterson算法. 像是为两个线程准备的spin锁<sup>注3</sup>。可以说是一个很巧妙的技巧，但似乎在当今平台上并没什么用处。值得注意的是由于Bartosz Milewski 在<a href="https://bartoszmilewski.com/2008/11/05/who-ordered-memory-fences-on-an-x86/" target="_blank" rel="external">讨论x86内存模型细节</a>的时候将Peterson算法作为案例研究(case study).其他人也在<a href="http://objectmix.com/c/742068-subtle-difference-between-c-0x-mm-other-mms.html" target="_blank" rel="external">类似的语境</a>下讨论过Peterson算法</li>
<li>Charles Bloom写了篇很长的文章讨论<a href="http://cbloomrants.blogspot.com/2011/07/07-15-11-review-of-many-mutex.html" target="_blank" rel="external">不同锁的实现</a>。文章提供了非常有价值的信息，但对那些对C++ 11原子库和<a href="http://www.1024cores.net/home/relacy-race-detector" target="_blank" rel="external">Relacy</a>不熟悉的人来说可能会望而却步。</li>
</ul>
<p>其中不乏非常先进的实现<sup>注4</sup>。本文则介绍一种相对简单的技术，会用到信号量和一些原子操作。当我写<a href="http://www.chongh.wiki/blog/2016/06/20/mutexperf/" target="_blank" rel="external">锁不慢;锁竞争慢</a>这篇文章时突然想到了这种方法,但不久后发现在1996年就已经有人用过了，那时候一些工程师把它叫做<a href="https://www.haiku-os.org/legacy-docs/benewsletter/Issue1-26.html#Engineering1-26" target="_blank" rel="external">Benaphore</a>. 下面是其在Win32平台下的C++实现(假设你使用的是X86 CPU架构).</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;windows.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;intrin.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> Benaphore</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    LONG m_counter;</span><br><span class="line">    HANDLE m_semaphore;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Benaphore()</span><br><span class="line">    &#123;</span><br><span class="line">        m_counter = <span class="number">0</span>;</span><br><span class="line">        m_semaphore = CreateSemaphore(NULL, <span class="number">0</span>, <span class="number">1</span>, NULL);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ~Benaphore()</span><br><span class="line">    &#123;</span><br><span class="line">        CloseHandle(m_semaphore);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">Lock</span><span class="params">()</span></span><br><span class="line">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (_InterlockedIncrement(&amp;m_counter) &gt; <span class="number">1</span>) <span class="comment">// x86/64 guarantees acquire semantics</span></span><br><span class="line">        &#123;</span><br><span class="line">            WaitForSingleObject(m_semaphore, INFINITE);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">Unlock</span><span class="params">()</span></span><br><span class="line">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (_InterlockedDecrement(&amp;m_counter) &gt; <span class="number">0</span>) <span class="comment">// x86/64 guarantees release semantics</span></span><br><span class="line">        &#123;</span><br><span class="line">            ReleaseSemaphore(m_semaphore, <span class="number">1</span>, <span class="literal">NULL</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>这种实现也可以作为对原子操作的简单介绍，它是许多无锁算法的核心。</p>
<p><code>_InterlockedIncrement</code>是Win32平台下的原子读改写(read-modify-write(RMW))操作<sup>注5</sup>.  在同一块数据上，如果多个线程同时执行原子RMW操作，需要排队等候，每次执行其中一个线程。这样一来，也能推断出到底发生了什么以确保正确性。它也能工作在多核与多处理器系统上。</p>
<p>每个现代处理器都提供了一些原子RMW指令，尽管其工具链提供的API在返回值上可能代表不同的含义。在Win32平台下，<code>_InterlockedIncrement</code>对整型数据执行加1操作并返回更新后的整型值。<code>m_counter</code>被初始化为0，第一个调用<code>Lock</code>的线程会从<code>_InterlockedIncrement</code>中得到返回值1. 这样就会跳过<code>WaitForSingleObject</code>调用，并立即返回。这把锁现在属于这个线程了，生活如此美好！</p>
<p>如果另一个线程调用<code>Lock</code>，而此时第一个线程正持有这把锁，此线程将会从<code>_InterlockedIncrement</code>中得到返回值2。这就意味着这把锁现在处于忙碌状态。此时，再继续执行下去是不安全的，我们只好自食其果，让其跳转到某个开销比较大的内核调用中：<code>WaitForSingleObject</code> 。其会对信号量执行减1操作。我们在<code>CreateSemaphore</code>中将信号量初始化为0，因此此线程现在会被强制等待直到另一个线程出现并将信号量增加，才能继续执行。</p>
<p>下一步，假设第一个线程调用<code>Unlock</code>。<code>_InterlockedDecrement</code>的返回值就是1. 这就意味着另一个线程正在等待这把锁，此时我们必须使用<code>ReleaseSemaphore</code>增加信号量。第二个线程才能继续执行，并拿到锁的持有权。</p>
<p>尽管时间很短，在第二个线程调用<code>WaitForSingleObject</code>之前第一个线程会调用<code>ReleaseSemaphore</code>，所有的过程都会正常执行。如果你此时添加第三个线程，第四个线程或者任意数量的线程，也无所谓。为了更好的测试，你可以在实现中增加一个<code>TryLock</code>函数</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">TryLock</span><span class="params">()</span></span><br><span class="line"></span>&#123;</span><br><span class="line">    LONG result = _InterlockedCompareExchange(&amp;m_counter, <span class="number">1</span>, <span class="number">0</span>);</span><br><span class="line">    return (result == <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="性能与弊端"><a href="#性能与弊端" class="headerlink" title="性能与弊端"></a>性能与弊端</h2><p>你可能已经注意到<code>_InterlockedIncrement</code>前面的下划线。这是<code>InterlockedIncrement</code>的<a href="https://en.wikipedia.org/wiki/Intrinsic_function" target="_blank" rel="external">编译器独有版本</a>. 它会在适当的地方输出<code>lock xadd</code>指令。由于<code>Lock</code>正好定义在<code>Benaphore</code>类内部，编译器将其看作是一个内联函数。当调用<code>Benaphore::Lock</code>的时候，编译器在默认的发行版设置会将其编译成10条指令，而在无竞争的情况下，则不会出现函数调用。以下是反汇编代码：<br><img src="http://7xppf1.com1.z0.glb.clouddn.com/ownlightwightmutex1.png" alt="ownlightweightmutex1"><br>在无竞争的情况下，Benaphore甚至比Win32平台下的Critical Section性能还要好。就像我在<a href="http://www.chongh.wiki/blog/2016/06/27/lightweightmutex/" target="_blank" rel="external">上一篇文章</a>对Mutex和Critical Section做过的测试一样，我也测试了Benaphore在无竞争情况下一对lock/unlock操作的时间。结果如下：</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/ownlightweightmutex2.png" alt="ownlightweightmutex2"></p>
<p>在Win32平台下，如果你有一个程序每秒钟使用一百万次锁，Benaphore的实现能将程序整体的性能提升几个百分点。 如果你使用原子操作的常规版本而非内置版本，会发生一次跳转到kernel32.dll，这是Benaphore就没什么优势了：在我的多核处理器上测试需要49.8ns.</p>
<p>并且，只要修改部分代码，你就可以在进程间共享Benaphore–这是Critical Section无法做到的。这时你必须将<code>m_counter</code>变量放进共享内存,并使用一个已经命名的信号量。然而，依赖于你使用的实例情况，这可能会破坏隔离进程的初衷。如果一个进程在不恰当的时间终止，可能会将Benaphore置于一种不一致的状态，然后终止其它进程.</p>
<p>这种实现是不可递归的.如果一些线程试图将同一个Benaphore锁上两次，就会出现死锁情况。我会在<a href="">下一篇</a>文章中，将这种实现扩展成可递归的.</p>
<p>如果将这些代码放到另一种CPU架构中运行，比如Xbox 360或者多核的i0S设备，必须把<code>_InterlockedIncrement</code>宏替换成可以显示提供<a href="http://preshing.com/20120913/acquire-and-release-semantics/" target="_blank" rel="external">acquire和release语义</a>的东西。</p>
<p>最后，如果你将Benaphore应用到其它平台，要当心它可能会出现<a href="https://en.wikipedia.org/wiki/Priority_inversion" target="_blank" rel="external">优先级反转</a>(priority inversion)问题<sup>注6</sup>。举个例子，MacOS X和Linux在使用POSIX锁的时候通过<a href="https://en.wikipedia.org/wiki/Priority_inheritance" target="_blank" rel="external">优先级继承</a>机制能避免优先级反转问题。 如果你使用的是Benaphore,会绕过这种操作系统机制，这并不会帮到你。但在Windows上情况是不一样的：不管你使用哪种同步原语，Windows都会通过提升饥饿进程的优先级来避免优先级反转问题。<sup>注7</sup></p>
<h2 id="译者注"><a href="#译者注" class="headerlink" title="译者注"></a>译者注</h2><p>注1：考虑单处理器上运行两个线程A和B，其中A持有spin lock；而B的优先级较高，当B在自旋时，由于它具有较高的优先级，导致A得不到调度因此无法释放锁，于是B也无法获得锁，出现活锁。</p>
<p>注意到作者说的是最坏的情况，实际上上述所说的这种情况一般不会出现，因为一般来说现代操作系统对线程的管理中，除了优先级之外还有时间片机制，不会出现A得不到调度的情况。</p>
<p>不知道作者所说的活锁是不是这种情况。如果我所说有错，恳请读者指正。</p>
<p>注2：一般说来，在实现spin lock的时候有一些优化的点。首先，需要区分单处理器和多处理器的情况；其次，在多处理器下，在自旋的过程中，随着尝试拿锁的失败次数越来越多，拿锁的间隔也应该越来越长，常用的是<code>Exponential Backoff</code>策略，间隔呈指数级上升。<code>pause</code>指令也常常在这个地方被使用，一是为了优化性能(和cpu指令预取有关)，二是节能减排。</p>
<p>注3：<code>peterson</code>算法原先是为两个线程互斥访问而设计的算法，它的出发点和核心是仅仅使用store和load(写读操作，不使用<code>CAS</code>也就是<code>compare and swap</code>原子操作等)来实现互斥访问。由于在现有体系结构下，为了性能，乱序执行已经是常态，因此仅仅使用读写操作而不用其他的机制例如<code>Memory Barrier</code>来实现<code>peterson</code>算法非常困难，再加上推广到多个线程的方法并不明显，因此在业界鲜为人用。</p>
<p>注4：实现spin lock的算法非常多，在《The Art Of Multiprocessor Programming》这本书的第七章中有详细的介绍，当contention非常严重的情况下，一种称为<code>MCS Queue Lock</code>的实现非常高效。另外，在实现spin lock的时候除了性能，还需要考虑多方面的指标：是否公平？是否满足先来先服务？scalability如何？等等等等。在保证公平这点上，<code>Ticket Lock</code>是妇孺皆知的算法，但是具有较差的scalability，更多细节感兴趣的朋友可以参考<a href="https://pdos.csail.mit.edu/papers/linux:lock.pdf" target="_blank" rel="external">这篇</a>论文。</p>
<p>注5：RMW中，有家喻户晓的CAS(<code>Compare And Swap</code>)、TAS(<code>Test And Set</code>)、FAA(<code>Fetch And Add</code>)等。为了实现这些原子变量，早期的Intel CPU使用锁住总线的方式(正如大家在很多资料中看到的)；现在，一般使用cache一致性来实现，先把其他CPU上对应的cache line都invalid掉，然后修改该变量的CPU把自己的cache line置为exclusive，就可以放心的更改了。</p>
<p>注6：为了解释优先级反转，考虑三个线程A、B、C，优先级分别为高中低。假设某时刻线程C持有锁，然后它被相对较高优先级的、cpu密集的线程B给抢占。当具有最高优先级的A尝试获得锁时，就反而被比它优先级低的B给block住了。这就是优先级反转。为了避免这种情况，除了文中介绍的常用的优先级继承这种机制外，简单的做法是线程持有spin lock的时候禁止抢占，而linux下则可以通过<code>futex</code>这种基础设施来避免优先级反转。</p>
<p>注7：本文都是考虑Windows下的实现，我们不妨一起来看看在Linux + X86下，如何利用gcc这种伟大的编译器来实现自己的锁。</p>
<p>不考虑scalability和性能，下面的非常简短的代码是一个简单spin lock实现：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> flag = <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">lock</span><span class="params">()</span></span><br><span class="line"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(__sync_lock_test_and_set(&amp;flag, <span class="number">1</span>)) &#123;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">unlock</span><span class="params">()</span></span><br><span class="line"></span>&#123;</span><br><span class="line">  __sync_lock_release(&amp;flag, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当然，也可以通过gcc内置的<code>__sync_bool_compare_and_swap</code>来实现，更多原子操作可以参考<a href="https://gcc.gnu.org/onlinedocs/gcc-5.4.0/gcc/_005f_005fsync-Builtins.html#_005f_005fsync-Builtins" target="_blank" rel="external">这里</a>。</p>
<p>为了实现一个忙则睡眠的锁，可以使用<code>futex</code>，不过相比，这里面的水就非常深了。以下是抛砖引玉的实现：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;linux/futex.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;sys/syscall.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CAS(address, a, b) __sync_bool_compare_and_swap(address, a, b)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ACCESS_ONCE(x) (*((volatile __typeof__(x) *) &amp;x))</span></span><br><span class="line"><span class="keyword">class</span> MyMutex</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  MyMutex()</span><br><span class="line">  &#123;</span><br><span class="line">    val = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">lock</span><span class="params">()</span></span><br><span class="line">  </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (CAS(&amp;val, <span class="number">0</span>, <span class="number">1</span>)) &#123;</span><br><span class="line">      return;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (ACCESS_ONCE(val) == <span class="number">2</span> || CAS(&amp;val, <span class="number">1</span>, <span class="number">2</span>)) &#123;</span><br><span class="line">        sys_futex(&amp;val, FUTEX_WAIT_PRIVATE, <span class="number">2</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">while</span> (!CAS(&amp;val, <span class="number">0</span>, <span class="number">2</span>));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">unlock</span><span class="params">()</span></span><br><span class="line">  </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (__sync_fetch_and_add(&amp;val, <span class="number">-1</span>) != <span class="number">1</span>) &#123;</span><br><span class="line">      val = <span class="number">0</span>;</span><br><span class="line">      sys_futex(&amp;val, FUTEX_WAKE_PRIVATE, <span class="number">1</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="function"><span class="keyword">static</span> <span class="keyword">long</span> <span class="title">sys_futex</span><span class="params">(<span class="keyword">void</span> *addr1, <span class="keyword">int</span> op, <span class="keyword">int</span> val1, <span class="keyword">struct</span> timespec *timeout, <span class="keyword">void</span> *addr2, <span class="keyword">int</span> val3)</span></span><br><span class="line">  </span>&#123;</span><br><span class="line">    return syscall(SYS_futex, addr1, op, val1, timeout, addr2, val3);</span><br><span class="line">  &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="keyword">int</span> val;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>免责声明：自己拨弄<code>futex</code>不是一个好主意，慎重。这里提供的代码仅供参考和提供进一步学习的方向，不对正确性和安全性负责。如果用于生产环境出了问题，我们不承担任何责任。</p>
<h3 id="Acknowledgement"><a href="#Acknowledgement" class="headerlink" title="Acknowledgement"></a>Acknowledgement</h3><p>本文由 <a href="http://weibo.com/2767520802/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="external">Diting0x</a> 与 <a href="http://weibo.com/yebangyu" target="_blank" rel="external">睡眼惺忪的小叶先森</a> 共同完成，在原文的基础上添加了许多精华注释，帮助大家理解。</p>
<p>感谢好友<a href="http://weibo.com/u/1707881862?topnav=1&amp;wvr=6&amp;topsug=1&amp;is_all=1" target="_blank" rel="external">小伙伴-小伙伴儿 </a>与<a href="http://weibo.com/u/2495479763?topnav=1&amp;wvr=6&amp;topsug=1&amp;is_all=1" target="_blank" rel="external">skyline09_ </a>阅读了初稿，并给出宝贵的意见。</p>
<p>原文： <a href="http://preshing.com/20120226/roll-your-own-lightweight-mutex/" target="_blank" rel="external">http://preshing.com/20120226/roll-your-own-lightweight-mutex/</a></p>
<p>本文遵守Attribution-NonCommercial-NoDerivatives 4.0 International License (CC BY-NC-ND 4.0)<br>仅为学习使用，未经博主同意，请勿转载<br>本系列文章已经获得了原作者preshing的授权。版权归原作者和本网站共同所有</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在&lt;a href=&quot;http://www.chongh.wiki/blog/2016/06/27/lightweightmutex/&quot;&gt;上一篇&lt;/a&gt;文章中，我强调了使用轻量级锁的重要性。还提到如果你能容忍某些弊端的话，自己动手实现轻量级锁也是可以的。&lt;/p&gt;
    
    </summary>
    
      <category term="High-performance" scheme="http://yoursite.com/categories/High-performance/"/>
    
    
  </entry>
  
  <entry>
    <title>深入探索并发编程系列(二)-总是使用轻量级锁</title>
    <link href="http://yoursite.com/blog/2016/06/27/lightweightmutex/"/>
    <id>http://yoursite.com/blog/2016/06/27/lightweightmutex/</id>
    <published>2016-06-27T15:36:21.000Z</published>
    <updated>2016-11-01T17:01:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>在多线程编程中，我们会常说起锁(也叫互斥量)。但锁仅仅是个概念，要真正用上锁，需要将其实现。事实证明，存在许多实现锁的方法，不同方法在性能表现上却有很大的区别。</p>
<a id="more"></a>
<p>Windows SDK为C/C++提供了锁的两种不同实现：Mutex和Critical Section。(正如Ned Batchelder <a href="http://nedbatchelder.com/blog/200304/mutexes_and_critical_sections.html" target="_blank" rel="external">这篇文章</a>指出的那样，Critical Section可能并不是对锁命名的最好方式，我们在这里就不去深究了)</p>
<p>Windows的Critical Section就是我们说到的轻量级锁。它是专为没有其它线程竞争锁的情况下而优化的。为了说明这点，下面举个例子，有个单线程lock/unlock一百万次，使用的是Windows的Mutex。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">HANDLE mutex = CreateMutex(NULL, FALSE, NULL);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; i++)</span><br><span class="line">&#123;</span><br><span class="line">    WaitForSingleObject(mutex, INFINITE);</span><br><span class="line">    ReleaseMutex(mutex);</span><br><span class="line">&#125;</span><br><span class="line">CloseHandle(mutex);</span><br></pre></td></tr></table></figure>
<p>用Windows的Critical Section也做同样的实验：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CRITICAL_SECTION critSec;</span><br><span class="line">InitializeCriticalSection(&amp;critSec);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; i++)</span><br><span class="line">&#123;</span><br><span class="line">    EnterCriticalSection(&amp;critSec);</span><br><span class="line">    LeaveCriticalSection(&amp;critSec);</span><br><span class="line">&#125;    </span><br><span class="line">DeleteCriticalSection(&amp;critSec);</span><br></pre></td></tr></table></figure>
<p>如果你分别在两种情况下的内部循环中添加计时代码，然后将结果除以一百万，就能得到一对lock/unlock操作的平均时间<sup>注1</sup>. 我照做了，并且在两个不同的处理器上做过实验。结果如下：</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/lightmutex1.png" alt="lightmutex"></p>
<p>Critical Section要快25倍。就像Larry Osterman 在<a href="https://blogs.msdn.microsoft.com/larryosterman/2005/08/24/why-dont-critical-sections-work-cross-process/" target="_blank" rel="external">Why don’t critical sections work cross process?</a>文章中解释的那样,每次使用Windows Mutex的时候都会进入到内核，Critical Section却不会。但其为此付出的代价是进程间不能共享Critical Section. 但是谁又会在意这个呢？绝大多数时候，你只想在单个进程内保护一些数据而已。（当然实际上也存在进程间共享轻量级锁的情况–那时候就别用Critical Section了)。细节可以参考下一篇文章:<a href="">自己动手实现轻量级锁 </a></p>
<p>现在假设你有个线程每秒钟获取Critial Section 100000次，这时没有其它线程竞争这把锁。基于上面得出的结果，锁的开销应该在0.2%和0.6%之间。不算太坏！在更低的频率下，开销就可以忽略不计了。</p>
<h3 id="其它平台"><a href="#其它平台" class="headerlink" title="其它平台"></a>其它平台</h3><p>在MacOS 10.6.6下，提供了<a href="https://en.wikipedia.org/wiki/POSIX_Threads" target="_blank" rel="external">POSIX Threads</a> API来实现锁。这是一种轻量级锁，除非存在竞争，否则是不会进入到内核的。在非竞争条件下，调用<code>pthread_mutex_lock</code>/<code>pthread_mutex_unlock</code>操作需要92ns（基于1.86GHz的Core双核CPU).有趣的是，当仅仅只有一个线程运行的时候，它能够检测到，这时会切换到一条trivial的代码路径中去处理，也仅需要38ns的时间。</p>
<p>MaxOS还提供了NSLock,一个Objective-C类，不过这仅仅是对前面提到的POSIX互斥量的封装。由于每个操作都要调用<code>objc_msgSend</code>方法，开销会大一些：需要155ns(基于上述CPU测试)，如果是单线程的话，需要98ns.</p>
<p>当然，Ubuntu 11.10也是用POSIX Threads API来实现锁的<sup>注2</sup>。这是另一种轻量级锁，其基于一种被称为<a href="https://en.wikipedia.org/wiki/Futex" target="_blank" rel="external">futex</a>的Linux特有的基础设施. 调用<code>pthread_mutex_lock</code>/<code>pthread_mutex_unlock</code>操作需要66ns. 你也可以在进程间共享锁，但我没测试过<sup>注3</sup>。</p>
<p>甚至连Playstation 3 SDK也提供了轻量级锁和重量级锁供大家选择。回想2007年，那时我参与开发的Playstation 3 游戏中，使用的还是重量级锁。当切换到轻量级锁的时候，游戏启动时间能加快17s. 对我来说，这种差异真是一针见血(hit home)。</p>
<p>在我 <a href="http://www.chongh.wiki/blog/2016/06/20/mutexperf/" target="_blank" rel="external">上一篇</a> 文章中，我为“锁是慢的”这个结论作了辩解并提供了一些支持我观点的数据。现在大家应该清楚，当你使用的不是轻量级锁的时候，整个观点便毫无意义了。我很清楚，由于重量级锁的存在让大家在过去几年对锁加深了一定的误解。</p>
<p>一些前辈可能会说在以前的老平台下，只有重量级锁的实现，或者说那时只能用信号量来完成任务。但现在大部分平台都提供了轻量级锁的实现。就算平台没有提供，你也可以在应用层实现自己的轻量级锁，如果你可以容忍一些弊端和警告的话，甚至还可以在进程间共享锁。我的下一篇文章将会告诉大家如何<a href="">自己动手实现轻量级锁</a>.</p>
<h3 id="译者注"><a href="#译者注" class="headerlink" title="译者注"></a>译者注</h3><p>注释1： 当然，合理的计时框架应该是这样的：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">log</span> start time;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; i++)</span><br><span class="line">&#123;</span><br><span class="line">  lock();</span><br><span class="line">  unlock();</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">log</span> end time;</span><br></pre></td></tr></table></figure>
<p>不过这里的结果是墙上时钟(Wall Clock)，而不是CPU时间。</p>
<p>注释2： Linux下提供了两种轻量级锁，分别为<code>pthread_spinlock_t</code>和<code>pthread_mutex_t</code>。前者属于busy loop类型，当没有获得锁时会通过一个while循环进行等待；对于后者，当线程无法成功拿到锁时会调用<code>system_wait</code>，当前线程加入到mutex对应的等待队列中。一般来说，当临界区较短或者一个core上只有一个线程时，和mutex相比，使用spin lock性能较佳，因为避免了上下文切换。</p>
<p>注释3：使用如下代码可以创建一把用于进程互斥的mutex:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pthread_mutexattr_t</span> mutexattr;  </span><br><span class="line">pthread_mutexattr_init(&amp;mutexattr);  </span><br><span class="line">pthread_mutexattr_setpshared(&amp;mutexattr,PTHREAD_PROCESS_SHARED);</span><br><span class="line"><span class="comment">//there is a mutex...</span></span><br><span class="line">pthread_mutex_init(&amp;mutex,&amp;mutexattr);</span><br></pre></td></tr></table></figure>
<p>当前，前提是mutex位于进程间的共享内存上。另外，进程间通信和互斥一般不使用mutex。</p>
<h3 id="Acknowledgement"><a href="#Acknowledgement" class="headerlink" title="Acknowledgement"></a>Acknowledgement</h3><p>本文由<a href="http://weibo.com/2767520802/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="external">Diting0x</a>与<a href="http://weibo.com/yebangyu" target="_blank" rel="external">睡眼惺忪的小叶先森</a> 共同完成，在原文的基础上添加了许多精华注释，帮助大家理解。</p>
<p>感谢好友<a href="http://weibo.com/u/1707881862?topnav=1&amp;wvr=6&amp;topsug=1&amp;is_all=1" target="_blank" rel="external">小伙伴-小伙伴儿 </a>与<a href="http://weibo.com/u/2495479763?topnav=1&amp;wvr=6&amp;topsug=1&amp;is_all=1" target="_blank" rel="external">skyline09_ </a>阅读了初稿，并给出宝贵的意见。</p>
<p>原文： <a href="http://preshing.com/20111124/always-use-a-lightweight-mutex/" target="_blank" rel="external">http://preshing.com/20111124/always-use-a-lightweight-mutex/</a></p>
<p>本文遵守Attribution-NonCommercial-NoDerivatives 4.0 International License (CC BY-NC-ND 4.0)<br>仅为学习使用，未经博主同意，请勿转载<br>本系列文章已经获得了原作者preshing的授权。版权归原作者和本网站共同所有</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在多线程编程中，我们会常说起锁(也叫互斥量)。但锁仅仅是个概念，要真正用上锁，需要将其实现。事实证明，存在许多实现锁的方法，不同方法在性能表现上却有很大的区别。&lt;/p&gt;
    
    </summary>
    
      <category term="High-performance" scheme="http://yoursite.com/categories/High-performance/"/>
    
    
  </entry>
  
  <entry>
    <title>深入探索并发编程系列(一)-锁不慢；锁竞争慢</title>
    <link href="http://yoursite.com/blog/2016/06/20/mutexperf/"/>
    <id>http://yoursite.com/blog/2016/06/20/mutexperf/</id>
    <published>2016-06-20T03:01:55.000Z</published>
    <updated>2016-11-01T17:01:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>锁(也叫互斥量)在很长一段时间都被误解了。1986年，在Usenet的有关于多线程的讨论会中，Matthew Dillon说过：大多数人都对锁有个误解，认为锁是慢的。25年后，这种误解似乎在某一时间段又突然出现了。</p>
<a id="more"></a>
<p>在某些平台上或者当锁被高度竞争时，锁确实慢。另外，当你在开发一个多线程程序时，由于锁的引入，给性能带来巨大的瓶颈是很常见的。但这并不意味着所有的锁都是缓慢的。我会在这篇文章中解释，有的时候，使用锁的策略反而能带来非常好的性能。</p>
<p>大家对锁的误解可能源自于某个最容易忽视的原因：不是所有的程序员都会意识到轻量级锁和内核锁的区别。我会在下一篇文章中对轻量级锁做专门介绍:<a href="http://www.chongh.wiki/blog/2016/06/27/lightweightmutex/" target="_blank" rel="external">总是使用轻量级锁</a>。在这篇文章中，假设你在Windows平台下做C/C++开发，你需要的正是一个<a href="https://msdn.microsoft.com/en-us/library/windows/desktop/ms682530.aspx" target="_blank" rel="external">Critical Section</a>对象。</p>
<p>有时候，锁是慢的这个结论是由benchmark支撑的。例如，这篇文章在高负载状态下来测试锁的性能：每个线程必须持有锁来完成任何一项任务（高竞争），并且锁都是在极短的时间间隔下被持有（高频率）。这种方式似乎很完美，但在实际应用中，却要避免这种使用锁的方式<sup>注1</sup>。基于这种考虑，我设计了一种benchmark，同时包含对锁使用的最坏情况和最好情况。</p>
<p>由于一些其它的考虑，大家可能不愿意用锁了。存在一系列的技术被称为无锁编程(或者不含锁编程<sup>注2</sup>）。无锁编程是极具挑战性的，但其本身可以在许多实际应用场景下带来高度的性能回报。据我所知，有些程序员会花费许多天甚至几周的时间来设计某种无锁算法，之后再做一系列测试，但在几个月后才发现隐藏的bug. 风险与回报并存对于相当一部分程序员都是有诱惑力的，这当然也包括我，在以后的几篇文章中会提到这些。有了无锁编程的诱惑，大家开始觉得锁使用起来很枯燥，缓慢并且非常糟糕。</p>
<p>但也不能把锁贬的一文不值。在现实软件中，当大家为了保护内存分配器的时候，锁就是一个让人敬仰的东西。<a href="https://techcrunch.com/2016/07/01/exploiting-machine-learning-in-cybersecurity/?ncid=rss&amp;utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+Techcrunch+%28TechCrunch%29" target="_blank" rel="external">Doug Lea的分配器</a>是在游戏开发中非常著名的内存分配器<sup>注3</sup>，但其只支持单线程，这时候我们就必须使用锁机制来进行保护。在游戏运行时，经常会碰到多个线程抢占一个内存分配器，每秒钟抢占次数可达到15000次左右。在加载过程中，每秒钟会达到100000次甚至更多。虽然这并不是个大问题。但你却可以看到，锁能非常出色的来处理这些负载。</p>
<h3 id="锁竞争benchmark"><a href="#锁竞争benchmark" class="headerlink" title="锁竞争benchmark"></a>锁竞争benchmark</h3><p>在这次测试中，我们创建一个线程来生成随机数，采用传统的<a href="https://en.wikipedia.org/wiki/Mersenne_Twister" target="_blank" rel="external">Mersenne Twister</a>生成器来实现。此线程时而获取锁，时而释放锁。获取与释放锁的间隔时间是随机的，但它都很接近我们提前决策出的平均值。举个例子，假设我们要每秒钟获取锁15000次，让持有锁的时间保持在总时间的50%. 下图是部分的timeline。红色说明锁正在被持有，灰色说明锁被释放。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/mutex1.png" alt="MUTEX1"></p>
<p>这是个泊松分布过程。如果我们知道生成单个随机数的平均时间–在2.66GHz的四核Xeon处理器上需要6.349ns–那么我们用工作单元(work units）而不是秒来衡量时间。可以用我之前的文章中介绍的方法,<a href="http://preshing.com/20111007/how-to-generate-random-timings-for-a-poisson-process/" target="_blank" rel="external">How to Generate Random Timings for a Poisson Process</a>,算出获取与释放锁的时间间隔有多少个工作单元。下面代码是C++的实现。我省略了一些细节，喜欢的话，可以在 <a href="http://7xppf1.com1.z0.glb.clouddn.com/mutex5.zip" target="_blank" rel="external">这里</a> 下载完整的源码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">QueryPerformanceCounter(&amp;start);</span><br><span class="line">for (;;)</span><br><span class="line">&#123;</span><br><span class="line">    // Do some work without holding the lock</span><br><span class="line">    workunits = (int) (random.poissonInterval(averageUnlockedCount) + 0.5f);</span><br><span class="line">    for (int i = 1; i &lt; workunits; i++)</span><br><span class="line">        random.integer();       // Do one work unit</span><br><span class="line">    workDone += workunits;</span><br><span class="line"></span><br><span class="line">    QueryPerformanceCounter(&amp;end);</span><br><span class="line">    elapsedTime = (end.QuadPart - start.QuadPart) * ooFreq;</span><br><span class="line">    if (elapsedTime &gt;= timeLimit)</span><br><span class="line">        break;</span><br><span class="line"></span><br><span class="line">    // Do some work while holding the lock</span><br><span class="line">    EnterCriticalSection(&amp;criticalSection);</span><br><span class="line">    workunits = (int) (random.poissonInterval(averageLockedCount) + 0.5f);</span><br><span class="line">    for (int i = 1; i &lt; workunits; i++)</span><br><span class="line">        random.integer();       // Do one work unit</span><br><span class="line">    workDone += workunits;</span><br><span class="line">    LeaveCriticalSection(&amp;criticalSection);</span><br><span class="line"></span><br><span class="line">    QueryPerformanceCounter(&amp;end);</span><br><span class="line">    elapsedTime = (end.QuadPart - start.QuadPart) * ooFreq;</span><br><span class="line">    if (elapsedTime &gt;= timeLimit)</span><br><span class="line">        break;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>现在假设我们运行两个这样的线程，每个线程运行在不同的CPU核心上。当执行任务时，每个线程有一半的时间是持有锁的，但如果其中一个线程在另一个线程持有锁的情况下试图获取锁，此线程会被强制等待。这就是锁竞争。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/mutex2.png" alt="MUTEX2"></p>
<p>在我看来，这是锁在实际程序中应用的非常好的例子。当我们运行上述的场景时，可以发现每个线程会花费25%的时间在等待，75%的时间在执行实际的任务。与单线程相比，两个线程都获得了1.5X的性能提升。</p>
<p>我在2.66GHZ的四核Xeon处理器上做过不同的测试，从一个线程到两个线程，一直到最多四个线程的情况，每个线程都分别运行在不同的CPU核心上。同时，我还改变锁被持有的时间，从锁绝不被持有，到每个线程必须100%的时间持有锁。在所有的case中，锁频率保持一个常数–在执行任务过程中，线程每秒钟获取锁15000次。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/mutex3.png" alt="MUTEX3"></p>
<p>结果很有意思。对于短的锁持有时间，比如持有时间占比&lt;10%的情况, 系统可能达到很高的并发性。虽然不是最完美的并发，但很接近。说明锁是非常快的！</p>
<p>为了把结果解释清楚一些，我用<a href="http://preshing.com/20111203/a-c-profiling-module-for-multithreaded-apis/" target="_blank" rel="external">这个分析器</a>分析了多线程游戏引擎中的内存分配锁.在游戏运行时，每秒钟有15000个锁来自三个线程，锁的持有时间在2%左右。正好落在图表中左侧的舒适区(comfort zone).</p>
<p>这些结果都表明一旦锁持有时间超过90%，就没有必要再使用多线程了。这时，单线程会表现的更好。同时，最让人吃惊的是4个线程的性能都急剧下降到60%左右。这看起来像是个异常情况，所以我又重新运行这些测试很多次了，甚至还改变了测试顺序。得到的结果却是一样的。我对此最好的解释就是，测试可能触碰到了Windows分配器的盲区，我没有更进一步的去研究这个问题。</p>
<h3 id="锁频率benchmark"><a href="#锁频率benchmark" class="headerlink" title="锁频率benchmark"></a>锁频率benchmark</h3><p>一个轻量级锁也会带来开销。正如我的<a href="http://www.chongh.wiki/blog/2016/06/27/lightweightmutex/" target="_blank" rel="external">下一篇</a>文章中说的,对Windows Critical Section的lock/unlock成对操作会花费23.5ns（基于上述测试的CPU). 因此可以说明，每秒钟有15000个锁已经足够少了，锁的开销并不会在很大程度上影响整个结果。但如果我们提高锁频率，又会发生什么呢？</p>
<p>算法中，严格控制锁与锁之间执行的任务数，因此我做了一系列新的测试：锁与锁的间隔时间从10ns到最高31ns(相对应每秒钟大约32000次锁).每次测试都使用两个线程。</p>
<p><img src="http://7xppf1.com1.z0.glb.clouddn.com/mutex4.png" alt="MUTEX4"></p>
<p>正如你想的那样，锁频率很高的话，锁本身的开销就已经高于所执行的任务本身了. 在网上找到的一些benchmarks,包括前面提到的那个分析器， 都落在图表中的右下角。在这些高频率下，和一些CPU指令的规模一样，锁的间隔比较小。好消息是，当锁与锁之间的任务比较简单的时候，无锁编程更可行。</p>
<p>与此同时，结果表明当锁频率达到每秒钟32000次时（锁间隔是3.1us)也是可以接受的。在游戏开发中，内存分配器就可能会在加载过程中达到这个频率。如果锁间隔比较短暂，你仍然可以得到1.5X的并发度。</p>
<p>我们已经了解了一系列锁性能的例子：有性能表现的很好的时候，也有性能慢的跟爬虫似的时候。我已经证明了游戏引擎中的内存分配器一直都能保持非常好的性能。把这个例子运用到实际场景中，不能说锁是慢的。不得不承认，锁很容易被滥用，但你不必太害怕–只要经过仔细的分析，任何情况下都能找出导致性能瓶颈的因素。当你正在考虑锁有多可靠，并去理解锁的相关优化方法时(相比无锁编程)，锁有时候表现的真的非常出色。</p>
<p>写这篇文章的目的是为了让锁得到应有的尊敬–欢迎批评指正。锁在工业应用程序中有广泛的应用，至于锁的性能，并不总是能达到一个很好的均衡。如果你在自己的经验中发现类似这样的例子，非常乐意看到你的评论<sup>注4</sup>。</p>
<h3 id="译者注"><a href="#译者注" class="headerlink" title="译者注"></a>译者注</h3><p>注释1:一种避免或者降低锁冲突的科学思想是partition，避免资源集中。例如，对于hashtable，可以由之前的一个hashtable对应一把锁，改为每个bucket配置一把锁，这样冲突将大大降低。再例如，计数程序，如果大家都对同一个全局变量进行读写而加一把锁，那么冲突严重，可以适当的选择多个计数器，不同的线程累加对应的计数器，一个线程负责将这些计数器的值求和。等等等等。</p>
<p>注释2: 这里的无锁编程，原文为lock free。不含锁编程，原文为lockless。但是需要注意的是，lock free并不是无锁的意思，它的本质是说一组线程，总有（至少）一个线程能make progress，和有没有锁没有本质联系。lock free目前一般都翻译为无锁（有些地方也翻译为锁无关），因此本文也采用这种译法，但是读者需要特别注意。另外lockless就是真正的无锁、不包含锁的编程。</p>
<p>注释3: Doug Lea是并发编程的大牛，《Java并发编程实战》的作者之一，非常乐意分享。他写的这个分配器非常出名，glibc所采用的内存分配器实现就是基于他设计的算法。</p>
<p>注释4: 本文的描述和试验可能让人有点迷糊，这里提供一下Paul E. McKenney大叔在他的著作《Is Parallel Programming Hard, And, If So, What Can You Do About It?》中第4章中的例子来解释，让读者更好的理解：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pthread_rwlock_t</span> rwl = PTHREAD_RWLOCK_INITIALIZER;</span><br><span class="line"><span class="keyword">int</span> holdtime = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> thinktime = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">long</span> <span class="keyword">long</span> *readcounts;</span><br><span class="line"><span class="keyword">int</span> nreadersrunning = <span class="number">0</span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> GOFLAG_INIT 0</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> GOFLAG_RUN  1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> GOFLAG_STOP 2</span></span><br><span class="line"><span class="keyword">char</span> goflag = GOFLAG_INIT;</span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">reader</span><span class="params">(<span class="keyword">void</span> *arg)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">   <span class="keyword">int</span> i;</span><br><span class="line">   <span class="keyword">long</span> <span class="keyword">long</span> loopcnt = <span class="number">0</span>;</span><br><span class="line">   <span class="keyword">long</span> me = (long)arg;</span><br><span class="line">   __sync_fetch_and_add(&amp;nreadersrunning, <span class="number">1</span>);</span><br><span class="line">   <span class="keyword">while</span> (ACCESS_ONCE(goflag) == GOFLAG_INIT) &#123;</span><br><span class="line">     <span class="keyword">continue</span>;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">while</span> (ACCESS_ONCE(goflag) == GOFLAG_RUN) &#123;</span><br><span class="line">     <span class="keyword">if</span> (pthread_rwlock_rdlock(&amp;rwl) != <span class="number">0</span>) &#123;</span><br><span class="line">       perror(<span class="string">"pthread_rwlock_rdlock"</span>);</span><br><span class="line">       <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">     &#125; </span><br><span class="line">     <span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;holdtime;i++)&#123;</span><br><span class="line">       barrier();</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">if</span> (pthread_rwlock_unlock(&amp;rwl) != <span class="number">0</span>) &#123;</span><br><span class="line">       perror(<span class="string">"pthread_rwlock_unlock"</span>);</span><br><span class="line">       <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">for</span> (i=<span class="number">1</span>;i&lt;thinktime;i++) &#123;</span><br><span class="line">       barrier();</span><br><span class="line">     &#125;</span><br><span class="line">     loopcnt++;</span><br><span class="line">   &#125;</span><br><span class="line">   readcounts[me] = loopcnt;</span><br><span class="line">   return <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> 其中16-18行等待测试开始的信号；19行开始测试；holdtime控制临界区的长短，thinktime用来控制两次申请锁之间的间隔。测试的时候有三个变量：holdtime、thinktime、线程数（1个、2个、4个、直到核数的两倍）。试试看。</p>
<h3 id="Acknowledgement"><a href="#Acknowledgement" class="headerlink" title="Acknowledgement"></a>Acknowledgement</h3><p>本文由 <a href="http://weibo.com/2767520802/profile?topnav=1&amp;wvr=6&amp;is_all=1" target="_blank" rel="external">@Diting0x</a> 与 <a href="http://weibo.com/yebangyu" target="_blank" rel="external">@睡眼惺忪的小叶先森</a> 共同完成，在原文的基础上添加了许多详细注释，帮助大家理解。</p>
<p>感谢好友<a href="http://weibo.com/u/2495479763?topnav=1&amp;wvr=6&amp;topsug=1&amp;is_all=1" target="_blank" rel="external">@skyline09_ </a>与<a href="http://weibo.com/u/1707881862?topnav=1&amp;wvr=6&amp;topsug=1&amp;is_all=1" target="_blank" rel="external">@小伙伴-小伙伴儿 </a>阅读了初稿，并给出意见。</p>
<p>原文： <a href="http://preshing.com/20111118/locks-arent-slow-lock-contention-is/" target="_blank" rel="external">http://preshing.com/20111118/locks-arent-slow-lock-contention-is/</a></p>
<p>本文遵守Attribution-NonCommercial-NoDerivatives 4.0 International License (CC BY-NC-ND 4.0)<br>仅为学习使用，未经博主同意，请勿转载<br>本系列文章已经获得了原作者preshing的授权。版权归原作者和本网站共同所有</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;锁(也叫互斥量)在很长一段时间都被误解了。1986年，在Usenet的有关于多线程的讨论会中，Matthew Dillon说过：大多数人都对锁有个误解，认为锁是慢的。25年后，这种误解似乎在某一时间段又突然出现了。&lt;/p&gt;
    
    </summary>
    
      <category term="High-performance" scheme="http://yoursite.com/categories/High-performance/"/>
    
    
  </entry>
  
</feed>
